{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":""},{"location":"#patfolio-a-journey-of-growth-and-serendipity","title":"PatFolio: A Journey of Growth and Serendipity","text":"<p>Welcome to the PatFolio, the digital log of my life. Although it is designed to serve as a PortFolio, it is more than one; it is a hub of ideas, knowledge and discovery. Within the confines of this virtual walls, you can find a blend of my projects, blog posts, a blossoming digital garden and so much more!</p> <p>Here, you can expect to explore the depths of my thinking as I come across and curate content that is interesting, thought provoking and possibly enlightning with an ambitious goal of topics ranging from <code>centering a div</code> to <code>center of human emotions</code>.  </p> <p>I wish to keep this project, not just about me. I want it to be about connecting with like-minded individuals, who share a thirst for knowledge and growth. Together, we can exchange ideas, insights and inspire one another to greater heights.</p> <p>Alright, ready to jump in?</p> <p>Explore the Digital Garden About me </p>"},{"location":"#what-is-a-digital-garden","title":"What is a Digital Garden?","text":"<p> A digital garden is a unique concept that takes the traditional notion of a blog or personal website to a whole new level. It is an evolving collection of thoughts, ideas, and insights that resembles a living, breathing ecosystem. In this virtual garden, information is cultivated, nurtured, and shared in an organic and interconnected manner.</p> <p>Unlike a static blog, a digital garden is designed to encourage exploration and discovery or in other words, serendipity. It allows ideas to grow and evolve over time, just like plants in a well-tended garden. Instead of presenting fully formed articles, a digital garden embraces the concept of \"half-baked\" ideas, providing a space for continuous learning and iteration.</p> <p>Within a digital garden, one can expect to find a network of interconnected thoughts and concepts. Each idea is like a seed planted in the soil, waiting to sprout and intertwine with other ideas. As one navigates through the garden, it is possible to follow the paths that are interesting and delve deeper into the topics that resonate, and make connections between different branches of knowledge.</p> <p>By exploring a digital garden, one can become an active participant in the process of knowledge creation. It's a collaborative journey where the gardener (author) and the visitors (readers) engage in a symbiotic relationship, nurturing the growth of ideas together.</p> <p>So step into my digital garden, wander through its pathways, and let your curiosity guide you towards a richer understanding of the world.</p>"},{"location":"#current-projects","title":"Current Projects","text":"<ol> <li>Building content-heavy static sites with MkDocs (Material Theme) - </li> </ol>"},{"location":"#latest-blog","title":"Latest Blog","text":""},{"location":"About-Me/","title":"About Me","text":""},{"location":"About-Me/#my-work","title":"My Work","text":""},{"location":"About-Me/#my-tech-stack","title":"My Tech Stack","text":"<p> Terraform |  AWS |  PowerShell</p> <p> Send Me a Mail</p>"},{"location":"Notes/Docker/","title":"Docker","text":""},{"location":"Notes/Docker/#introduction-to-docker","title":"Introduction to Docker","text":"<p>Containerization technology has been around for longer before Docker popularized it. But it was Docker which made the containerization technology accessible to the common people.</p>"},{"location":"Notes/Docker/#docker-the-technology-vs-docker-the-company","title":"Docker - The Technology vs Docker - The Company","text":"<p>The term Docker could refer to two things,</p> <ol> <li>Docker, Inc. - The company behind developing the product.</li> <li>Docker - One of the the products the company offers.</li> </ol>"},{"location":"Notes/Docker/#a-brief-history-about-docker-inc","title":"A brief history about Docker, Inc.","text":"<p>Docker, Inc is an American technology company that develops tools around the containers and technologies that enable it. The company was founded in 2008 with the name dotCloud by Kamel Founadi, Solomon Hykes and Sebastian Pahl in Paris and later moved to the US in 2010. The company was renamed to Docker in 2013. </p> <p>Check out more about the company through Docker, Inc. website. The above paragraph is condensed from Wikipedia, check here for the Wikipedia article</p> <p>Some of the popular products of Docker, Inc. include, - Docker Hub - A central repository of containers. - Docker Desktop - Desktop GUI for Windows and Mac platforms.</p> <p>Docker also offers several pricing tiers with varied feature set. Check out Docker's pricing page here.</p>"},{"location":"Notes/Docker/#a-brief-history-about-docker","title":"A brief history about Docker","text":""},{"location":"Notes/Docker/#from-linux-to-everywhere","title":"From Linux to everywhere","text":"<p>Docker traditionally was developed to work on the Linux OS, but slowly with Microsoft's contributions and close support with Docker, Inc. the platform is also available for Windows. This gave birth to 2 types of containers namely,</p> <ol> <li>Linux Containers - Runs on Windows, Mac and Linux</li> <li>Windows Containers - Runs on Windows</li> </ol> Linux ContainersWindows Containers <pre><code>docker pull ubuntu:latest\n</code></pre> <pre><code>docker pull mcr.microsoft.com/powershell:lts-nanoserver-1903\n</code></pre> <p>As containers share the kernel of the host operating system, Windows containers cannot run on a Mac or Linux. However, thanks to Microsoft's support for Linux, Windows containers as well as Linux containers can run on Windows.</p>"},{"location":"Notes/Docker/#docker-installation","title":"Docker Installation","text":"<p>Refer the Docs for the latest information on instructions for how to install docker for the platform of your choice. Docker is available (thanks to the contribution of countless open source contributions) on Linux, Windows and Mac. However, the way the containerization is implemented varies slightly across the platforms.</p>"},{"location":"Notes/Docker/#docker-architecture","title":"Docker Architecture","text":"<p>Docker follows a simple client-server architecture along with a central repository to store and serve the images. Thus, there are 3 main components in a docker implementation.</p> <ol> <li>Client<ul> <li>It connects to the docker engine to send and receive commands and outputs.</li> <li>It could be a GUI Application such as Docker Desktop (available for Windows and Mac) or a CLI Tool available for Docker CLI (Windows, Mac and Linux).</li> <li>Client can exist on the same machine as the Docker Engine or exist on a different machine.</li> </ul> </li> <li>Server<ul> <li>This is</li> <li>It performs all operations related to containers throughout their lifetime.</li> <li>Often referred to as <code>dockerd</code> (pronounced as <code>docker-dee</code>).</li> <li>It manages several container objects such as images, containers, volumes, networks and other plugins.</li> </ul> </li> <li>Repository<ul> <li>A storage location for container images.</li> <li>It could be the official repository from Docker Inc., Docker Hub or from a third-party provider such as AWS, Azure or GCP or locally maintained by a company.</li> </ul> </li> </ol> <p>Communication between docker client and docker engine happens over REST API. Docker engine runs on port 2376 by default.</p>"},{"location":"Notes/Docker/#client","title":"Client","text":"<ul> <li>The docker client provides a primary way for the users to interact with docker.</li> <li>It provides an interface to manage container objects such as images, containers, volumes, networks and other plugins.</li> <li> <p>Docker client is available as</p> <ol> <li>Docker CLI - Available in Windows, Mac and Linux.</li> <li>Docker Desktop - Available on Windows and Mac.</li> </ol> </li> </ul>"},{"location":"Notes/Docker/#engine","title":"Engine","text":"<p>The docker engine can be considered as the software that runs, manages and terminates the containers as per the user's requirements. Docker engine (currently-2023) is modular in nature and is made up of smaller specialized tools that adhere to open standards such as the Open Container Initiative or OCI.</p>"},{"location":"Notes/Docker/#monolithic-docker-engine-from-the-past","title":"Monolithic Docker Engine from the past","text":"<p>When docker was initially released, the docker engine had two components.</p> <ol> <li>Docker Daemon or <code>dockerd</code> - a singular daemon that contained the code for client, API, container runtime and more.</li> <li>LXC (Linux Containers)- An OS-level virtualization technology that allows creation and management of multiple isolated Linux virtual environments on a single control host</li> </ol> <p>The docker daemon was built as a monolith that performs several functionalities and LXC was specific to Linux, thus threatening the cross-platform ambition of docker.</p> <p>LSX was soon replaced with <code>libcontainer</code> developed in-house by Docker. Inc. to provide a cross-platform functionality to docker. <code>libcontainer</code> replaced LXC as the execution driver in docker 0.9.</p> <p>The next priority was to breakdown the monolithic docker daemon into microservices. This gave rise to tools such as <code>runc</code>, <code>containerd</code> and <code>shim</code> discussed below.</p>"},{"location":"Notes/Docker/#open-container-initiative-oci","title":"Open Container Initiative (OCI)","text":"<p>The Open Container Initiative or the OCI is an open governance standard/structure for the purpose of creating industry standards around container formats and runtimes. OCI was established in 2015 by Docker and other industry leaders in the container industry.</p> <p>OCI currently contains 3 specifications</p> <ol> <li>Runtime Specification (<code>runtime-spec</code>)</li> <li>Image specification (<code>image-spec</code>)</li> <li>Distribution Specification (<code>distribution-spec</code>)</li> </ol>"},{"location":"Notes/Docker/#docker-in-its-present-state","title":"Docker in its present state","text":"<p>Currently (2023), Docker engine is made up of the following components.</p> <ol> <li>docker daemon or <code>dockerd</code><ul> <li>The docker daemon or <code>dockerd</code> provides an interface between the docker client and the core docker functionalities.</li> <li>The client communicates to <code>dockerd</code> via REST API and <code>dockerd</code> delegates the tasks and performs the actions as directed from the client.</li> <li>From being a monolithic implementation to a microservices focussed tool, most of the <code>dockerd</code>'s initial functionality is stripped into their own services.</li> <li>Currently, the daemon is responsible for image management, image builds, REST API communication, authentication, security, core network</li> </ul> </li> <li><code>containerd</code><ul> <li>Its main functionality is to manage container lifecycle.</li> <li>It interfaces between the daemon and <code>runc</code></li> <li>Initially it set out to be a lightweight container management tool, it soon took additional functionality of managing other objects such as images, volumes and networks.</li> <li>However, as <code>containerd</code> is very modular, most of the functionality can be added only if required, thus keeping the size small.</li> <li><code>containerd</code> is currently a graduated CNCF project.</li> </ul> </li> <li><code>shim</code> <ul> <li><code>shim</code> promotes the concept of daemon-less containers.</li> <li>It is used to decouple the container runtimes from the <code>containerd</code> service.</li> <li>This is advantageous as the now-decoupled environment is not dependent on <code>containerd</code> for its operation, thus allowing <code>containerd</code> and thereby the daemon to be started, stopped or upgraded without killing all the running containers.</li> <li>Every time a new container needs to be started, a new fork of the <code>runc</code> is created.</li> <li><code>runc</code> then starts the container and then exists.</li> <li><code>shim</code> then takes over the process and manages the containers by keeping the STDIN and STDOUT streams open and reporting container's exit status back to the daemon.</li> </ul> </li> <li><code>runc</code><ul> <li>It is the reference implementation of the OCI <code>runtime-spec</code>. </li> <li><code>runc</code> is referred to operating at the OCI layer.</li> <li>It is a lightweight CLI wrapper for <code>libcontainer</code>  interfacing between the host kernel and the container.</li> <li>At its core, the functionality of <code>runc</code> is to start containers and it is very efficient at doing that.</li> <li><code>runc</code> can be replaced with any other OCI <code>runtime-spec</code> compatible runtimes.</li> </ul> </li> </ol>"},{"location":"Notes/Docker/#image-repositoryregistry","title":"Image Repository/Registry","text":"<p>Docker Hub is the most popular image repository/registry to upload and manage docker images (OCI compatible images). It offers features such as image versions (tags), public and paid repositories and much more. There are several pricing options that offer varied support and feature set.</p> <p>There are other image repositories as well. Some of the other popular ones include</p> <ul> <li>Amazon Elastic Container Registry by AWS.</li> <li>Azure Container Registry by Azure.</li> <li>Container Registry by Google Cloud (GCP)</li> </ul>"},{"location":"Notes/Docker/#communication-via-rest-api","title":"Communication via REST API","text":"<p>Communication between the client, docker engine and the image repository occurs via REST API. This is implemented by the docker daemon.</p> <p>Docker can be set up in two ways</p> <ol> <li>Docker Client and Docker Engine on the same host - Communication over the IPC socket.</li> <li>Docker Client and Docker Engine on different hosts - communication over the network</li> </ol>"},{"location":"Notes/Docker/#client-and-engine-on-same-host","title":"Client and Engine on Same Host","text":"<p>In a default installation, the docker client and the docker engine are setup in the same host. In such cases the communication is made via the local IPC socket.</p> <p>Example</p> <p>Unix Domain Socket (UDS) or Inter-Process Communication (IPC) Socket is a data communications endpoint for exchanging data between processes running on the same host operating system. It is a standard component of the POSIX operating systems.</p> <p>In an IPC Socket communication, all communication occurs entirely within the operating system kernel. </p> <p>The socket can be found at <code>/var/run/docker.sock</code> on Linux and at <code>//./pipedocker_engine</code> on Windows. </p>"},{"location":"Notes/Docker/#client-and-engine-on-different-host","title":"Client and Engine on Different Host","text":""},{"location":"Notes/Docker/#docker-objects","title":"Docker Objects","text":"<p>Docker comprises of several entities referred commonly as objects. These are</p> <ol> <li>[[Docker#Images|Images]] - Templates that are used when containers are created and used.</li> <li>[[Docker#Containers|Containers]] - Running/operational instance of an image.</li> <li>[[Docker#Volumes|Volumes]] - Persistent storage for data created and stored during container runtimes.</li> <li>[[Docker#Networks|Networks]] - Constructs of networking that enable containers to communicate within themselves and outside of the docker environment to the docker host and to other external networks.</li> <li>[[Docker#Networks|Networks]] - Optional functionalities across domains such as volume, networking, authentication and so on that can be added to the docker engine.</li> </ol>"},{"location":"Notes/Docker/#images","title":"Images","text":"<ul> <li>Images are one of the core parts of a docker implementation.</li> <li>They are templates from which containers are created.</li> <li>Hence images are considered as build-time constructs.</li> <li>Once a container is created from an image, they both become dependent on each other, thus the image cannot be destroyed unless all of the containers that use the image are stopped and removed. </li> <li>Images are usually small in size as they contain the barebones of what is required to run the app or service or environment and nothing else. Containers use the host's operating system for lower level tasks, hence the light weightiness of the images.</li> <li>However, Microsoft's images on windows are a little bit larger in size due to the architecture of the Windows Operating System.</li> </ul>"},{"location":"Notes/Docker/#pulling-images","title":"Pulling Images","text":"<p>The process of downloading an image from a repository is referred to as pulling. Docker defaults to Docker Hub as source repository, however it is possible to change the repository when pulling the images and the process remains the same nonetheless. </p> docker pull command<pre><code>docker pull ubuntu:latest\n</code></pre> <p>If the image did not exist prior locally, it is pulled as given below.</p> docker pull output - new pull<pre><code>latest: Pulling from library/ubuntu\n677076032cca: Pull complete\nDigest: sha256:9a0bdde4188b896a372804be2384015e90e3f84906b750c1a53539b585fbbe7f\nStatus: Downloaded newer image for ubuntu:latest\ndocker.io/library/ubuntu:latest\n</code></pre> <p>However, if the image already exists locally, the following information is given by the docker engine back to the client.</p> docker pull output - existing image<pre><code>latest: Pulling from library/ubuntu\nDigest: sha256:9a0bdde4188b896a372804be2384015e90e3f84906b750c1a53539b585fbbe7f\nStatus: Image is up to date for ubuntu:latest\ndocker.io/library/ubuntu:latest\n</code></pre> <p>What happens if an image that does not exist is requested for a pull?</p> <pre><code>docker pull totally-fake-image\n</code></pre> <p>The action returns the following response.</p> <pre><code>Using default tag: latest\nError response from daemon: pull access denied for totally-fake-image, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\n</code></pre> <p>To pull all images in a repository (usually not recommended) pass the <code>-a</code> flag to the docker pull command.</p> <pre><code>docker pull -a image\n</code></pre>"},{"location":"Notes/Docker/#listing-the-locally-stored-images","title":"Listing the locally stored Images","text":"<p>To list the images that are currently available locally, the following commands can be used.</p> <pre><code>docker images\ndocker image ls\n</code></pre> <p>Docker then displays all the images that are available locally.</p> <pre><code>REPOSITORY   TAG       IMAGE ID       CREATED       SIZE\npostgres     latest    680aba37fd0f   2 weeks ago   379MB\nnode         latest    272b8142e84e   2 weeks ago   998MB\nmysql        latest    57da161f45ac   2 weeks ago   517MB\nubuntu       latest    58db3edaf2be   4 weeks ago   77.8MB\n</code></pre> <p>The <code>docker image ls</code> command allows to filter the output of the docker images returned based on certain criteria such as</p> <ul> <li>dangling (Accepts Boolean) - Untagged images which usually occur when newer images are built with the tag that exists prior. Docker removes the tag from the older version of the image and attaches the tag to the newer image, thus leaving the older image without tags.</li> <li>before (Accepts image name/ID) - Returns all the images created before the supplied image.</li> <li>since (Accepts image name/ID) - Returns all the images created after the supplied image.</li> <li>label (Accepts string) - Returns the images based on the presence of a label or value. However, the docker images ls command does not display labels in its output.</li> </ul> <p>Docker also supports filtering using reference (additional functioning features) and the usage Go templates using the <code>--format</code> flag.</p> <pre><code># List images that are devoid of tags\ndocker image ls --filter dangling=true\n# List images that have tags\ndocker image ls --filter dangling=false\n# List images before the curious-salamander \ndocker image ls --filter before=\"curious-salamander\"\n# List images after the curious-salamander\ndocker image ls --filter since=\"curious-salamander\"\n# List images with Go Templates formatting\ndocker image ls --format \"{{.Repository}}: {{.Tag}} - {{.Size}}\"\n</code></pre>"},{"location":"Notes/Docker/#image-naming","title":"Image Naming","text":"<p>Each and every image is labelled in a container registry to make it easier to identify the image. A standard image nomenclature is given below.</p> <pre><code>registry-link/repository-link/image-name:tag\n</code></pre> <ul> <li><code>registry-link</code><ul> <li>DNS name of the image registry.</li> <li>Instructs docker client of which registry to use.</li> <li>This is optional, will resolve to Docker Hub registry if no input is provided.</li> </ul> </li> <li><code>repository-link</code><ul> <li>Name of the repository that hosts the image of interest.</li> <li>Official images are stored by Docker Hub in the top-level of the docker Hub namespace.</li> <li>This is not used if the image under question resides on the top level domain in Docker Hub.</li> <li>For third-party images, repository link is mandatory.</li> </ul> </li> <li><code>image-name</code><ul> <li>Denotes the actual name of the image of interest.</li> <li>This is a mandatory field.</li> </ul> </li> <li><code>tag</code><ul> <li>Denotes a variant of the image within the repository.</li> <li>it is just a string used for easy identification.</li> <li>Usually, repositories would have an incrementing numeric progression.</li> <li>The latest version, by convention is also tagged as latest to facilitate easy identification.</li> <li>However, it might not be the case always and it entirely depends on the developer and maintainer of the image</li> <li>The same image can have more than one tags as repositories do not restrict with content.</li> <li>It is always best practice to refer the documentation of the respective images to better understand the naming convention of the tags used foe the particular image.</li> </ul> </li> </ul>"},{"location":"Notes/Docker/#searching-the-repository","title":"Searching the repository","text":"<p>To search for a particular image, the <code>docker search</code> command can be used. However it only searches the NAME field. By default, Docker displays only 25 hits, which can be increased to 100 with the limit flag.</p> <pre><code>docker search alpine --limit 5\n</code></pre> <p>This returns all the images with the text alpine in the NAME field.</p> <pre><code>NAME                               DESCRIPTION                STARS     OFFICIAL   AUTOMATED\nalpine                             A minimal Docker image \u2026   9724      [OK]\nalpinelinux/docker-cli             Simple and lightweight \u2026   7\nalpinelinux/gitlab-runner          Alpine Linux gitlab-run\u2026   4\nalpinelinux/alpine-gitlab-ci       Build Alpine Linux pack\u2026   3\nalpinelinux/gitlab-runner-helper   Helper image container \u2026   2\n</code></pre>"},{"location":"Notes/Docker/#made-up-of-layers","title":"Made up of Layers","text":"<p>An image in Docker is made up of several layers of files that make up the final image. This is done to make the images modular. Docker finally stacks the layers and displays them as a single image. This is done to make docker efficient in operation and avoid constant re-download of existing layers from other images.</p> <p>Suppose, if an ubuntu image has to be downloaded for the latest version, it might share the underlying layers from the previous versions of ubuntu. In that case, only the new layers are downloaded and the existing ones are used as such. </p> <p>Layers are represented using their SHA256 hashes. This is used by docker to identify and use the layers across images without downloading the same layer again for another image.</p> <p>The number of layers is based upon what the image does, the core applications it runs and that base image was used to build the image.</p> <p>These layers can be seen when trying to pull and image. To know the different layers that make up an image, use the <code>docker image inspect</code> command.</p> <pre><code>docker image inspect &lt;container-name/container-ID&gt;:&lt;tag&gt;\n</code></pre> <p>Behind the scenes, docker employs a storage driver that enables the layer stacking and presenting them as a single file system. However, the user experience remains identical in each case.</p> <p>Inspecting images also provide a way to under stand the default process that will run upon the container start from the image. This is usually found within the CMD or the ENTRYPOINT sections of the <code>json</code> object the inspect command returns.</p>"},{"location":"Notes/Docker/#content-hashes-digests-and-immutability","title":"Content Hashes, Digests and Immutability","text":"<p>Docker 1.10 introduced the concept of content hashes, where each and every image gets a cryptographic content hash which is a representation of  the contents of an image. This makes it impossible to change the contents of an image  without changing the hash. This is referred to as digest, which are a way to uniquely identify an image.</p> <p>When an image is pulled, the docker client shows the digest associated with the image. To show all the images along with their digest, use the --digest flag to <code>docker images</code> command</p> <pre><code>docker images --digest\n</code></pre> <pre><code>REPOSITORY   TAG       DIGEST               IMAGE ID       CREATED       SIZE\npostgres     latest    sha256:901df89014\u2026   680aba37fd0f   2 weeks ago   379MB\nnode         latest    sha256:33e99abf6c\u2026   272b8142e84e   2 weeks ago   998MB\nmysql        latest    sha256:8653a170e0\u2026   57da161f45ac   2 weeks ago   517MB\nubuntu       latest    sha256:9a0bdde418\u2026   58db3edaf2be   4 weeks ago   77.8MB\n\n# NOTE: The digest hash is truncated for better visibility\n</code></pre> <p>Currently, there is no provision to get the digest has for images in a remote registry. To get the digest of an image, the image needs to be pulled locally.</p>"},{"location":"Notes/Docker/#deleting-images","title":"Deleting Images","text":"<p>Deleting images can be done by using the docker <code>images rm</code> or the <code>docker rmi</code> command. Deleting an image remove the layers corresponding to the image from the host. However, if any of the layers is shared across multiple other images, the layer is not removed until all other images are also deleted.</p> <pre><code># Delete images (command 1)\ndocker image rm &lt;image-name/image-ID&gt;\n\n# Delete images (command 2)\ndocker rmi &lt;image-name/image-ID&gt;\n\n# Deleting multiple images\ndocker rmi &lt;image-1-name/image-1-ID&gt; &lt;image-2-name/image-2-ID&gt;\n\n# Deleting all existing images\ndocker rmi $(docker images -q)\n</code></pre>"},{"location":"Notes/Docker/#containers","title":"Containers","text":"<p>Docker implements containers adhering to the OCI runtime, image and specifications, thus making them compatible to be run on other containerization platforms also following the OCI standards. A container is the runtime instance of an image. It can be considered similar to a VM instance, but it is much faster and lightweight than a typical VM. Also Containers share the OS/Kernel of the host and install only the libraries and dependencies required by the application or service that the container hosts. </p>"},{"location":"Notes/Docker/#run-containers-basics","title":"Run Containers (basics)","text":"<p>Containers can be run from an image which can be either locally available or hosted in an image registry. If locally available, containers are spun up from the local copy of the image. If the images are not available locally, they are pulled from the remote registry and then the containers are spun up. Thus, containers can only be spun from a local copy of images, which makes them dependent during runtime.</p> <pre><code>docker run -it centos:latest /bin/bash\n</code></pre> <p>The following outputs results in case the image does not exist locally.</p> <pre><code>Unable to find image 'centos:latest' locally\nlatest: Pulling from library/centos\na1d0c7532777: Pull complete\nDigest: sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177\nStatus: Downloaded newer image for centos:latest\n[root@adcd9bc897de /]#\n</code></pre> <p>In case a copy of the image is found locally, the following output can be obtained where the container is started straightaway.</p> <pre><code>[root@e5da8ec268a1 /]#\n</code></pre>"},{"location":"Notes/Docker/#listing-containers","title":"Listing Containers","text":"<p>The following command(s) can be used to list the containers currently managed by the docker engine.</p> <pre><code># List running containers (command 1)\ndocker container ls\n\n# List running containers (command 2)\ndocker ps\n\n# List all containers (stopped and running)\ndocker ps -a\n</code></pre> <p>Upon executing the commands given above, the following output can be obtained.</p> <pre><code># Listing just the running containers\nCONTAINER ID   IMAGE           COMMAND        CREATED         STATUS         PORTS     NAMES\nb83c2173f913   centos:latest   \"sleep 1000\"   3 seconds ago   Up 2 seconds             wonderful_wilson\n\n# Listing all the containers (stopped and running)\nCONTAINER ID   IMAGE           COMMAND        CREATED              STATUS                          PORTS     NAMES\nb83c2173f913   centos:latest   \"sleep 1000\"   About a minute ago   Up About a minute                         wonderful_wilson\n464420bfbaba   centos:latest   \"/bin/bash\"    About a minute ago   Exited (0) About a minute ago             gifted_robinson\ne5da8ec268a1   centos:latest   \"/bin/bash\"    10 minutes ago       Exited (0) 2 minutes ago                  objective_banach\nadcd9bc897de   centos:latest   \"/bin/bash\"    11 minutes ago       Exited (0) 10 minutes ago                 gracious_borg\n</code></pre>"},{"location":"Notes/Docker/#stopping-running-containers","title":"Stopping Running Containers","text":"<p>To stop running containers, the following command(s) can be used.</p> <pre><code># Stop a single Container (command 1)\ndocker container stop curious_mongoose\n\n# Stop a single Container (command 2)\ndocker stop curious_mongoose\n\n# Stop a multiple Containers\ndocker stop angry_shark 1b24b6409429\n\n# NOTE: Both container Name and Container ID can be used interchangeably.\n# NOTE: First few characters (uniqueness required) are enough when using ID\n</code></pre> <p>Docker engine then returns the name/Id that was supplied to denote that the containers have been stopped.</p> <pre><code># Stop a single Container\ncurious_mongoose\n\n# Stop a multiple Containers\nangry_shark\n1b24b6409429\n</code></pre> <p>An important note to take is that a container runs as long as a main task is designated to it. Without a process, the container terminates. Thus, here are a couple of things to keep in mind.</p> <ol> <li>Starting a container without a main process, terminates it immediately.</li> <li>Killing the main process of a running container, terminates the container.</li> </ol> <p>To exit a container without killing the container, use the shortcut <code>Ctrl + P + Q</code></p>"},{"location":"Notes/Docker/#start-a-stopped-container","title":"Start a Stopped Container","text":"<p>To start a stopped container, use the following command</p> <pre><code># Start a stopped container (command 1)\ndocker container start curious_mongoose\n\n# Start a stopped container (command 2)\ndocker start curious_mongoose\n\n# NOTE: Both container Name and Container ID can be used interchangeably.\n</code></pre> <p>A couple of important things to keep in mind when stopping and starting containers.</p> <ol> <li>Stopping and Starting a container does not destroy the data within it.</li> <li>However, if a container is terminated, the data is lost.</li> </ol> <p>Containers can be configured to automatically restart based on a restart policy. These restart policies are container scoped. Following are the restart policies currently available</p> <ul> <li><code>always</code> - Always restart containers</li> <li><code>unless-stopped</code> - Restart unless explicitly stopped</li> <li><code>on-failed</code> - Restart if the container fails and terminates</li> </ul>"},{"location":"Notes/Docker/#removingdeleting-containers","title":"Removing/Deleting Containers","text":"<p>To remove a container completely. the <code>docker container rm</code> command can be used.</p> <pre><code># Remove (delete) a container (Command 1)\ndocker container rm happy_otter\n\n# Remove (delete) a container (Command 2)\ndocker rm sad_kangaroo\n\n# Remove (delete) all existing containers (forcefully)\ndocker rm $(docker ps -aq) -f\n\n# NOTE: Both container Name and Container ID can be used interchangeably.\n</code></pre> <p>The <code>docker rm</code> command can be used to stop and terminate (delete/remove) a container in one go. However, it abruptly terminates the container. The differences between using <code>docker stop</code> and <code>docker rm</code> to stop a container is the signal it sends to the main process running inside the container.</p> <ol> <li><code>docker stop</code> issues the SIGTERM command and it provides the containers to complete the existing task and terminate gracefully. If the container does not stop, a SIGKIILL command is issued.</li> <li><code>docker rm</code> issues the SIGKILL command straightaway, thus abruptly terminating the container.</li> </ol>"},{"location":"Notes/Docker/#accessing-the-container-logs","title":"Accessing the Container Logs","text":"<p>Logs can be an effective way to identify and troubleshoot issues. To access the logs of a container, use the following command.</p> <pre><code>docker logs keen_meninsky\n</code></pre> <p>This lists all the logs of the container named <code>keen_meninsky</code></p> <pre><code>root@f1b513b37415:/# whoami\nroot\nroot@f1b513b37415:/# man grep\nThis system has been minimized by removing packages and content that are\nnot required on a system that users do not log into.\n\nTo restore this content, including manpages, you can run the 'unminimize'\ncommand. You will still need to ensure the 'man-db' package is installed.\n</code></pre>"},{"location":"Notes/Docker/#running-containers-more-options","title":"Running Containers (more options)","text":"<p>Containers can be given additional instructions when they are started. Following are some of the most common information that can be passed when starting containers</p> <pre><code># Run container in detached mode (leaves current terminal free to use)\ndocker run -d ubuntu:latest\n\n# Attach tthe STDIN, STDERR and STDOUT of a container to terminal\ndocker -a proud_jackfruit\n\n# Run container in interactive mode (i) and leave the terminal open (t)\ndocker run -it ubuntu:latest\n\n# Execute a command on a container upon start\ndocker run ubuntu:latest sleep 100\n# Explicitly name a container (replaces the randomly generated name)\ndocker run --name my-demo-environment ubuntu:latest\n\n# Map a port from host to container (Format - Host:Container)\ndocker run -p 8080:80 httpd:2.4.55\n\n# Pass values to environment variables (can be checked with inspect command)\ndocker run -e MYSQL_ROOT_PASSWORD=my-secret-pw mysql:latest\n</code></pre> <p>Check out the list of options that can be supplied from Docker Docs </p>"},{"location":"Notes/Docker/#volumes","title":"Volumes","text":"<p>By default, all data stored within a container's runtime storage is deleted when the container is terminated. Volumes are a way to manage that behavior to allow to create non-persistent and persistent storage for data as required. </p> <ol> <li>Non-Persistent Data<ul> <li>Default storage mode for containers</li> <li>The data is wiped as soon as the container is terminated.</li> <li>Thus, the data lifecycle is coupled with the container lifecycle.</li> </ul> </li> <li>Persistent Data<ul> <li>Data persists beyond the lifecycle of the container.</li> <li>Volumes provide a way to persist data.</li> </ul> </li> </ol>"},{"location":"Notes/Docker/#non-persistent-data","title":"Non-Persistent Data","text":"<p>Containers are considered to be immutable, meaning that they are read-only entities. However, a read-write layer is essential to run certain processes on containers. This is provided by means of storage drivers. Following are the storage drivers currently available.</p> <ul> <li>Storage Drivers available on Linux<ul> <li><code>AUFS</code></li> <li><code>overlay2</code></li> <li><code>devicemapper</code></li> <li><code>btrfs</code></li> <li><code>zfs</code></li> </ul> </li> <li>Storage Drivers on Windows<ul> <li><code>windowsfilter</code></li> </ul> </li> </ul>"},{"location":"Notes/Docker/#persistent-data","title":"Persistent Data","text":"<p>Volumes are the most common way to maintain persistent data within containers. Following are three points to keep in mind as to why volumes are preferred to run persistent storage in containers. - Volumes are independent - volumes are not tied to the lifecycle of the container, hence the container can be stopped, removed and restarted, but the data would persist. - Volumes can be mapped to external storage - Volumes can be mapped to external storage services both on-premises and on cloud, thus allowing them to share storage with other machines. - Volumes can be mounted to multiple containers - Volumes provide features to attach them to multiple containers at the same time.</p> <p>Note</p> <p>Volumes in Docker are first-class citizens and have their own object in the API. Thus some sub-commands might mean different thing entirely in volumes as to what it would mean in the context of an image or a container.</p>"},{"location":"Notes/Docker/#create-a-volume","title":"Create a Volume","text":"<p>To create a new volume, use the following command</p> <pre><code># Create Docker Volumes\ndocker volume create my-first-volume\n</code></pre> <p>This by default creates a docker volume with the <code>local driver</code>. Several other general and purpose built drivers are available as third party plugins providing Docker and thereby the containers running on Docker, seamless access to data across a wide variety of sources, formats and file systems.</p>"},{"location":"Notes/Docker/#listing-all-volumes","title":"Listing all Volumes","text":"<p>To list all the volumes available locally, use the following command</p> <pre><code># List Docker Volumes\ndocker volume ls\n</code></pre> <p>Docker Engine responds with the list of all volumes locally available.</p> <pre><code>DRIVER    VOLUME NAME\nlocal     6d406a6bfc9f2a4fd7c80f8a9f908437374ec861d2c4ca76519af2699bdb4c7f\nlocal     3877ee1f1a0d095e20b3a67b11e33259c8adb077947c10e61a56ab983f6206db\nlocal     a573c7afa8ec51e9970a75a49017de551790906b60512c83833c57728d999b0e\n</code></pre> <p>This shows the list of volumes with the <code>DRIVER</code> being used along with the <code>VOLUME NAME</code>. Unless specifically created, it shows the hash for the volume.</p>"},{"location":"Notes/Docker/#inspect-volumes","title":"Inspect Volumes","text":"<p>To know more information about a volume in question, the <code>inspect</code> command can be used as below</p> <pre><code># Inspect a Docker Volume\ndocker volume inspect my-first-volume\n</code></pre> <p>This produces an output with details about the volume.</p> <pre><code>[\n    {\n        \"CreatedAt\": \"2023-02-28T01:12:49Z\",\n        \"Driver\": \"local\",\n        \"Labels\": {},\n        \"Mountpoint\": \"/var/lib/docker/volumes/my-first-volume/_data\",\n        \"Name\": \"my-first-volume\",\n        \"Options\": {},\n        \"Scope\": \"local\"\n    }\n]\n</code></pre>"},{"location":"Notes/Docker/#attach-volumes","title":"Attach Volumes","text":""},{"location":"Notes/Docker/#delete-volumes","title":"Delete Volumes","text":"<p>Docker Volumes can be deleted with the following commands</p> <ol> <li><code>docker volume rm</code> - (SINGLE ACTION) Deletes specific volumes supplied by their volume names.</li> <li><code>docker volume prune</code> - (MASS ACTION) Deletes all volumes that are currently not attached to a container or service.</li> </ol> <pre><code># Delete specific volumes\ndocker volume rm my-first-volume\n\n# Delete all non-attached volumes\ndocker volume prune\n</code></pre> <p>Docker shows the following output</p> <pre><code># docker volume rm - for unattached volumes\nmy-first-volume\n\n# docker volume rm - or attached volumes\nError response from daemon: remove important-volume: \nvolume is in use - [1b77d...9c7]\n\n# docker volume prune\nWARNING! This will remove all local volumes not used by at least one container.\nAre you sure you want to continue? [y/N] y\nDeleted Volumes:\na573c7afa8ec51e9970a75a49017de551790906b60512c83833c57728d999b0e\n3877ee1f1a0d095e20b3a67b11e33259c8adb077947c10e61a56ab983f6206db\n6d406a6bfc9f2a4fd7c80f8a9f908437374ec861d2c4ca76519af2699bdb4c7f\n\nTotal reclaimed space: 1.71GB\n</code></pre>"},{"location":"Notes/Docker/#mount-volumes-to-containers","title":"Mount Volumes to Containers","text":""},{"location":"Notes/Docker/#using-volume-plugins","title":"Using Volume Plugins","text":"<p>Volume Plugins are a way to extend the persistent data functionality across multiple cloud platforms and service providers. Docker Hub allows third party volume plugins to be hosted. Installing plugins can be done with the following command</p> <pre><code>docker plugin install purestorage/docker-plugin:latest --alias pure --grant-all-permissions\n</code></pre> <p>Danger</p> <p>When writing data to a shared volume, there might be instances where the container holds the data in local buffer before committing to the shared volume. If multiple containers perform this delayed update, it is possible that the container that updates the data at the last might overwrite the existing data.</p> <p>To avoid this, the application or service that might access the shared volume must be developed in a way to circumvent the overwrite issue. </p>"},{"location":"Notes/Docker/#networks","title":"Networks","text":""},{"location":"Notes/Docker/#architecture-and-implementation","title":"Architecture and Implementation","text":"<p>At its highest level, networking in docker is comprised of 3 major components.</p> <ol> <li>Container Network Model (CNM) - Provides the Specification of network implementation.</li> <li>Libnetwork - Implementation of CNM for Docker.</li> <li>Drivers - Offers support for network topologies.</li> </ol>"},{"location":"Notes/Docker/#container-network-model-cnm","title":"Container Network Model (CNM)","text":"<p>Container Network Model provides the design fundamentals for networking in docker. CNM can be divided into 3 main building blocks.</p> <ol> <li>Sandboxes<ul> <li>Isolated network stacks, containing ethernet interfaces, ports, routing tables and DNS config.</li> </ul> </li> <li>Endpoints<ul> <li>Virtual network interfaces.</li> <li>Responsible for making connections. </li> </ul> </li> <li>Networks<ul> <li>These are software implementations of a network switch acting as a 802.1d bridge.</li> <li>They group together and isolate a collection of endpoints that need to communicate.</li> </ul> </li> </ol> <p>A connection between two containers needs to be explicitly established by means of networks connected via endpoints.</p>"},{"location":"Notes/Docker/#libnetwork","title":"Libnetwork","text":"<p>While CNM provided the basis and guidelines for the architecture, Libnetwork is the actual implementation of the CNM for Docker. Libnetwork is written in Golang and is cross-platform.</p> <p>Previously the docker daemon used to perform all the networking and routing. But moving towards a cloud native, microservices based architecture favoring the Unix ideology of modular tools that perform specific function well, the networking part of the daemon was refactored into Libnetwork.</p> <p>Libnetwork also implements native service discovery, ingress-based container load balancing and the network control plane &amp; management plane functionality.</p>"},{"location":"Notes/Docker/#network-drivers","title":"Network Drivers","text":"<p>While Libnetwork implements the network control plane and the management plane, the network drivers implement the data plane. Here, connectivity, isolation and creation of networks is handled by the drivers. </p> <p>By default, docker ships with several network drivers (commonly referred to as local drivers or native drivers). In Linux, these include <code>bridge</code>, <code>overlay</code>, <code>macvlan</code>. On Windows, these could be <code>nat</code>, <code>overlay</code>, <code>transparent</code> and <code>l2bridge</code>. There are several other third party network drivers available on Docker Hub for varied use cases.</p> <p>Each of these drivers are responsible for the actual creation and management of resources on the network they manage. </p> <p>At any given time, there can be multiple network drivers active, promoting a fluid environment and therefore Docker supports a wide range of heterogeneous networks. </p>"},{"location":"Notes/Docker/#working-with-networks","title":"Working with Networks","text":"<p>:::note Docker Network as First-Class Citizens Networks in Docker are first-class citizens and have their own object in the API. Thus some sub-commands might mean different thing entirely in networks as to what it would mean in the context of an image or a container. :::</p>"},{"location":"Notes/Docker/#create-networks","title":"Create Networks","text":"<p>To create a network in Docker, use the following command</p> <pre><code># Create networks in docker (by specifying driver)\ndocker network create -d bridge MyLocalNetwork\n</code></pre> <p>Upon successful creation, the Docker engine shows the hash of the thus created network.</p> <pre><code>a98dddd335c41d115e89a3fb7113f8360a1b2d8cc3d8346a05c960c6fff42959\n</code></pre>"},{"location":"Notes/Docker/#listing-all-networks","title":"Listing All Networks","text":"<p>To list all the active networks maintained by the Libnetwork associated with the local Docker engine, use the following command</p> <pre><code># List available Docker Networks\ndocker network ls\n</code></pre> <p>This returns a similar list as follows based on what networks are locally configured and maintained.</p> <pre><code>NETWORK ID     NAME             DRIVER    SCOPE\na98dddd335c4   MyLocalNetwork   bridge    local\nafe897982312   bridge           bridge    local\n7280ae463ec3   host             host      local\n</code></pre>"},{"location":"Notes/Docker/#inspect-networks","title":"Inspect Networks","text":"<p>One of the most powerful tools when working with networks in docker, the inspect command provides valuable insights.</p> <pre><code># Inspect a Docker Volume\ndocker network inspect MyLocalNetwork\n</code></pre> <p>This produces an output with details about the volume.</p> <pre><code>[\n    {\n        \"Name\": \"MyLocalNetwork\",\n        \"Id\": \"ead060ef929e747f2be0bdedb7182a4047c3a8dbaeab63a6e103581dd4532abd\",\n        \"Created\": \"2023-03-01T17:05:04.12407108Z\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": {},\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.21.0.0/16\",\n                    \"Gateway\": \"172.21.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {},\n        \"Options\": {},\n        \"Labels\": {}\n    }\n]\n</code></pre>"},{"location":"Notes/Docker/#delete-networks","title":"Delete Networks","text":"<p>Docker networks can be deleted with the following commands 1. <code>docker network rm</code> - (SINGLE ACTION) Deletes specific networks supplied by their network Names or Network ID. 2. <code>docker network prune</code> - (MASS ACTION) Deletes all networks that are currently not attached to a container or service.</p> <pre><code># Delete specific networks\ndocker network rm Secret-Salamander\n\n# Delete all non-attached networks\ndocker network prune\n</code></pre> <p>Docker shows the following output</p> <pre><code># docker network rm - for unattached volumes\nmy-first-volume\n\n# docker network rm - or attached network\nError response from daemon: remove Secret-Salamander: \nNetwork is in use - [1b77d...9c7]\n\n# docker network prune\nWARNING! This will remove all custom networks not used by at least one container.\nAre you sure you want to continue? [y/N] y\nDeleted Networks:\nminikube\nmongo-network\nMyLocalNetwork\n</code></pre>"},{"location":"Notes/Docker/#plugins","title":"Plugins","text":""},{"location":"Notes/Docker/#build-images-with-dockerfile","title":"Build Images with Dockerfile","text":"<p>Containers are immutable infrastructure, meaning no changes are made extensively once the application is deployed. In order to run containers, images are required as templates. Images can be built as per requirement by using a Dockerfile.</p> <p>A Dockerfile provides a way to create images. It guides the Docker engine on the requirements to build an image as per the specifications supplied. The directory in which the application and dependencies exist is referred to as the build context. Dockerfile usually exists at the build context directory. Dockerfile is always written as Dockerfile with the first letter capital and without spaces. Also, a Dockerfile does not have an extension (its just Dockerfile).</p>"},{"location":"Notes/Docker/#dockerfile-syntax-reference","title":"Dockerfile Syntax Reference","text":"<p>The template for a typical Dockerfile follows the below given syntax.</p> <pre><code># Comment\nINSTRUCTION arguments\n</code></pre> <ul> <li>Here, the <code>INSTRUCTION</code>'s are not case-sensitive but by convention are written in uppercase to identify instructions from arguments. </li> <li>Dockerfile instructions are executed in order from top to bottom.</li> </ul> <p>The following snippet captures some of the most commonly used <code>INSTRUCTION</code> types and an example of how to use them.</p> <pre><code># DemoDirective=\n# Dummy Dockerfile - Demonstration Purpose\nFROM alpine                              </code></pre>"},{"location":"Notes/Docker/#structure-and-formatting","title":"Structure and Formatting","text":"<ul> <li>Comments (Optional)<ul> <li>Comments in a Dockerfile are marked with a <code>#</code> at the beginning.</li> <li>However, parser directives can also start with a <code>#</code></li> <li>Unless the line is a parser directive, all comments are ignored by the Docker Daemon when processing the Dockerfile.</li> </ul> </li> <li>Parser Directives (Optional)<ul> <li>Parser Directives affect the way the subsequent lines are handled in a Dockerfile.</li> <li>They are structured as special kind of comment in the form of <code># directive=value</code>. </li> <li>Parser Directives cannot be repeated and can appear only once.</li> </ul> </li> <li>Environment Variables (Optional)<ul> <li>sdf</li> </ul> </li> <li>.dockerignore (Optional)<ul> <li>It can be used to exclude files and directories from being sent to the Docker Daemon.</li> <li>Docker CLI looks for a file named <code>.dockerignore</code> in the root of the context.</li> <li>If found, the CLI modifies the contents of the entities to exclude the files and directories before it sends to the daemon.</li> <li>It can be used to exclude files and folders being sent with the <code>ADD</code> and <code>COPY</code> instructions</li> <li>A typical .<code>dockerignore</code> file is provided below for reference.</li> </ul> </li> </ul> <pre><code># Comment\n/temp*\n*/secrets*\n*/*/logs*\ntemp?\n</code></pre> Syntax Reference What they mean in a <code>.dockerignore</code> file <code># comment</code> Ignored - no action taken <code>*/temp*</code> Excludes files and subdirectories starting with <code>temp</code> from the root of the context. <code>*/secrets</code> Excludes files and subdirectories one level down the root that start with <code>secrets</code> <code>temp?</code> Excludes files and subdirectories that start with <code>temp</code> and have one more character at the root of the context."},{"location":"Notes/Docker/#dockerfile-instructions-and-arguments","title":"Dockerfile Instructions and Arguments","text":"<ul> <li>FROM (Mandatory)<ul> <li>This instruction is mandatory and always must be the first instruction at the top of the Dockerfile. However there can be comments preceding it.</li> <li>Specifies the base image from which the current image is to be built.</li> <li>To build an image from scratch, use the official <code>scratch</code> image from Docker Hub. </li> </ul> </li> <li>RUN (Optional)</li> </ul>"},{"location":"Notes/Docker/#building-the-images","title":"Building the Images","text":""},{"location":"Notes/Docker/#pushing-the-images-to-a-registry","title":"Pushing the Images to a Registry","text":""},{"location":"Notes/Docker/#deployment-with-docker-compose","title":"Deployment with Docker Compose","text":""},{"location":"Notes/Docker/#container-orchestration-with-docker-swarm","title":"Container Orchestration with Docker Swarm","text":""},{"location":"Notes/Docker/#networking","title":"Networking","text":""},{"location":"Notes/Docker/#overlay-networking","title":"Overlay Networking","text":""},{"location":"Notes/Docker/#persisting-data-with-volumes","title":"Persisting Data with Volumes","text":""},{"location":"Notes/Docker/#app-deployment-with-stacks","title":"App Deployment with Stacks","text":""},{"location":"Notes/Docker/#focussing-on-security","title":"Focussing on Security","text":"<p>[[Docker Cheat Sheet]]</p>"},{"location":"Notes/Docker/#building-images-with-dockerfile","title":"Building Images with Dockerfile","text":"<ul> <li>Pull a container image from a repository: <code>docker pull image:tag</code></li> <li>Run a container: <code>docker run image:tag</code></li> <li>Docker ps command: <code>docker ps &lt;flags&gt;</code> --&gt; <code>docker ps -a</code> (all containers, running or not)</li> <li>Docker stop command: <code>docker stop &lt;container_name/container_id&gt;</code></li> <li>Docker rm command: <code>docker rm &lt;container_name/container_id&gt;</code></li> <li>List local images: <code>docker images</code> or <code>docker images ls</code></li> <li>Execute a command on a container: <code>docker exec &lt;container_name/container_id&gt; &lt;command&gt;</code></li> <li>Running in detached mode: <code>docker run -d image:tag</code></li> <li>Attach a detached container: <code>docker attach &lt;container_name/container_id&gt;</code></li> </ul>"},{"location":"Notes/Git/","title":"Git","text":""},{"location":"Notes/Git/#introduction-to-git","title":"Introduction to git","text":""},{"location":"Notes/Git/#story-of-git","title":"Story of git","text":"<p>[[Linux]] Operating being Open Source maintains its kernel code accessible to the public. During the early years of maintenance (1991 - 2002), the changes to the kernel were passed around as patches and archived files.</p> <p>In 2002, the Linux Kernel Project began using a proprietary [[Version Control System#Distributed Version Control Systems (DVCS)|DVCS]] software by the name BitKeeper. In 2005 the relationship between the Linux community and the BitKeeper software company broke and the tool's free-of-charge status was revoked.</p> <p>This prompted the Linux Community and primarily [[Linux Torvalds]] to develop their own tool based on the learnings and short comings of the previous system. On conception, Git had a few goals - Speed of operation - Simplicity in design - Strong support for non-linear development (parallel branching) - Fully distributed - Handle large projects</p> <p>Since 2005, when Git saw its initial release, the system has always stuck to these goals that it set out with initially. Today Git is one of the most popular distributed version control systems and it is free to use and open source.</p>"},{"location":"Notes/Git/#where-it-differs","title":"Where it differs","text":"<p>git fundamentally differs from the other VCS tools available in each of the following ways.</p> <ol> <li>Snapshots<ul> <li>Other VCS tools generally look for the differences in data between each file and store data on a per file basis (referred to as delta-based version control).</li> <li>Git on the other hand, takes complete snapshots of the overall state of the files and stores the information only on files that have changed. This enables Git to be mindful of what data needs to be updated in its tracking. If a file did not change, it merely refers to the last tracked version that was changed. In a way, it appears as a stream of snapshots.</li> </ul> </li> <li>Operations done Locally<ul> <li>Almost all the operations that Git does is done locally on the machine. This makes Git really fast when compared to CVCS systems which are network latency based for the speed of operation.</li> <li>It also gives the freedom to work on the files without being connected to a network. All changes can be stored offline and committed to the local copy of the repository.</li> </ul> </li> <li>Integrity<ol> <li>Every action in Git is checksummed before it is stored and it can be referred to by that checksum. This means that every action that occurs on the files is tracked by Git, either success or failure of action. Thus, information cannot be lost or corrupted without git knowing it.</li> <li>Git internally uses SHA-1 hash which is a 40 character hexadecimal value computed based on the contents of a file or directory structure in Git. Git stores everything in its database by hash value of its contents. A SHA-1 hash looks like  <code>24b9da6552252987aa493b52f8696cd6d3b00373</code>.</li> </ol> </li> <li>Data Addition<ul> <li>Git always adds data to its database and it is very difficult to mess things up that is not undoable.</li> <li>If commits are frequently and promptly made, data can be recovered to any state as required.</li> </ul> </li> </ol>"},{"location":"Notes/Git/#git-states","title":"Git states","text":"<p>By default, git does not track a file unless explicitly asked to. Thus all files in a git repository can be either tracked or untracked 1. Tracked - Git was explicitly asked to track changes to the file. 2. Untracked - Git was not asked to track changes to the file.</p> <p>Files that are being actively tracked by git can have 4 states 1. Unmodified - Files are are not changed from the last snapshot or checkout from the original source. 1. Modified - Files have been changed/modified, but not stored in the git database. 2. Staged - Files that have are set to be saved in the git database in the next snapshot. 3. Committed - Files that have been saved in the git database.</p> <p>These states are cyclic in nature. When a file is committed, it is sent back to the unmodified state, as there are not changes from the last snapshot or checkout. But subsequently when changes are made to the file, it goes into the modified state, which can then be staged and eventually committed, thus performing the cycle all over again.</p> <p>With this in mind, all git projects have 3 sections namely, 1. Working Tree/Directory - Where the tracked and untracked files reside. 2. Staging Area - Where the files that are set to be saved in the next snapshot reside. Physically, it is present in the <code>.git</code> directory. In git terminology, it is referred to as <code>index</code>. 3. <code>.git</code> directory - This is where git stores all the metadata and object database for the git project.</p>"},{"location":"Notes/Git/#git-and-command-line","title":"Git and command line","text":"<p>The Power of Git comes with its support on the command-line. Although Git contains several open-source and paid GUI clients available, most of them implement a subset of git's capability. This makes the command line the only place where git shines with its full capability.</p>"},{"location":"Notes/Git/#up-and-running-with-git","title":"Up and running with git","text":""},{"location":"Notes/Git/#git-installation","title":"Git installation","text":"<p>Git is available on Windows, Linux and MacOS Operating Systems. The instructions to download and setup Git varies based on the operating system and further information on the same can be found at Git - Downloads.</p>"},{"location":"Notes/Git/#git-setup","title":"Git setup","text":"<p>Git comes with a tool called as <code>git config</code> that allows to set up git as per preferences. Configurations can be set on 3 levels, namely 1. System Level at <code>[path]/etc/gitconfig</code> - Applied to every user in the system. 2. User Level at  <code>/.gitconfig</code> or <code>/.config/git/config</code> - Applies to the current user in the system. 3. Repo Level at <code>config</code> file at <code>.git</code> directory - Applies to the currently repository the use is currently working on.</p> <p>Each level of config overrides the previous level configuration. To get a list of all git configurations, run the following command.</p> <pre><code># Show configurations\ngit config --list\n# Show configurations and their origin\ngit config --list --show-origin\n</code></pre> <p>The following are some of the most common configuration settings that are done when setting up a local git environment. 1. Setting up identity - Used to authenticate the user and their actions. 2. Setting up default editor - Sets up default code editor for the actions that git launches. Options include Emacs, Vim, Notepad++, VS Code, Sublime Text or Atom. 3. Setting up default branch name - Git and other platforms are moving from the terminology of <code>master</code> to other names to be more inclusive. Most users prefer the term <code>main</code> to be their default branch name.</p> <pre><code># Identity Configurations\ngit config --global user.name \"John Doe\" \ngit config --global user.email johndoe@example.com\n# Editor Configurations\ngit config --global core.editor vscode\n# Default Branch Configurations\ngit config --global init.defaultBranch main\n</code></pre>"},{"location":"Notes/Git/#getting-help","title":"Getting help","text":"<p>Manuals and help in git can be accessed in a number of ways. These are showcased below.</p> <pre><code># For full-blown help/manual page\ngit help &lt;verb&gt;\ngit &lt;verb&gt; --help\nman git-&lt;verb&gt;\n# For compressed, available options for commands\ngit &lt;verb&gt; -h\n</code></pre>"},{"location":"Notes/Git/#git-repositories","title":"Git repositories","text":"<p>In the context of Git, a repository or a repo is a central location where code and its related files are stored and managed. It is basically a directory or folder where git tracks and manages directories, subdirectories and files.</p> <p>These git repositories can be hosted on various platforms such as  [[GitHub]], GitLab, Bitbucket or even self-hosted.</p> <p>The tracking made by Git in these repositories are what allows git to facilitate code rollbacks, comparisons and so on.</p>"},{"location":"Notes/Git/#initializing-git-repositories","title":"Initializing git repositories","text":"<p>In order to make git track a particular directory of interest (create a git repo), git needs to be specifically informed to track the directory. Git does not globally track all changes. This process is called as initialization and it is done to create new git repositories. Initialization of git repositories is done via the <code>git init</code> command</p> Initializing a git repository<pre><code># Initialize git repository in the current directory\ngit init .\n\n# Initialize git repository in another directory\ngit init \"C:\\Users\\UniqueUser\\Learning Git\\RealRepo\"\n# Initialize a git repository with a different main branch name\ngit init -b primary\n\n# Initialize a git repository - less verbose\ngit init -q\n</code></pre> <p>he command creates a <code>.git</code> directory with subdirectories for <code>objects</code>, <code>refs/heads</code>, <code>refs/tags</code> and template files. It also creates an initial branch without any commits (name based on the settings - global preference or local options via flags). </p> <p>Note: If a destination directory path is not provided, git initializes a repository in the current location.</p> <p>[!success] <code>git init</code> twice? Running <code>git init</code> on a repository more than once is not an issue. The command is commonly rerun when new templates are added or to move the repository to another place if separate git directory is given.</p> <p>[!caution] Just initializing does not track files It is to be noted that just initializing a repository does not track the files in the directory. In order to track the files, the files have to be added to the git tracking and then committed. This is covered later.</p> <p>[!danger] Gitception - Do not initialize git repos inside other repositories It is not good practice to have git tracked repositories inside git repositories making a nested git repository case. Some conflicts might arise and is generally discouraged.</p> <p>However there are ways to deal with managing existing git repositories that are used as a part of a current project. These ways are dealt later.</p>"},{"location":"Notes/Git/#getting-the-status-of-a-repo","title":"Getting the status of a repo","text":"<p>The status of a git repository states the current condition of the repository under question. It is used to know the following things about a directory.</p> <ol> <li>Branch information - It shows the name of the current branch that the repository is on.</li> <li>Staging area information - It shows the status of files in the staging area, including which files have been modified and which files are ready to be committed.</li> <li>Untracked files - It shows a list of files that are in the repository's working directory but have not yet been added to the staging area.</li> <li>Upstream branch information - It shows whether the current branch has an upstream branch and whether the local branch is ahead or behind the upstream branch.</li> <li>Conflicts - It shows if there are any conflicts in the repository that need to be resolved before changes can be committed.</li> </ol> Getting the status of a git repository<pre><code>git status\n</code></pre> Output from git status command<pre><code>On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   README.md\n</code></pre> <p>Note: It can also state if a git repository exists in a particular directory. The following snippet shows how git status reports if there is no git repository in the directory of interest.</p> Output from git status command<pre><code>fatal: not a git repository (or any of the parent directories): .git\n</code></pre>"},{"location":"Notes/Git/#saving-changes-to-a-repo","title":"Saving changes to a repo","text":"<p>Saving changes to a repository is done in two steps, each with a specific purpose.</p> <ol> <li>Staging - Move the changes to be committed to the staging area.</li> <li>Committing - Actually writing the state to the version history</li> </ol>"},{"location":"Notes/Git/#staging-changes-in-a-repo","title":"Staging changes in a repo","text":"<p>Staging in the context of git refers to the process of preparing changes made to a file or files for commit. Staging facilitates the users to selectively choose which changes must be committed, allowing the commits to be focused and organized.</p> <p>[!info] Keeping the commits atomic Care must be taken to make sure that a commit should encompass a single change or feature or a fix. In simpler terms, each commit must be focussed on one things only. This is done to facilitate easier undo and rollbacks and makes the code easier to follow and review.</p> <p>To stage changes in a git repository, the <code>git add</code>  command is used.</p> Staging changes in a git repository<pre><code># Staging a specific file\ngit add myfile.txt\n\n# Staging multiple files\ngit add myfile.txt README.md # Staging all changes\ngit add .\n</code></pre> <p>Upon running the command, <code>git status</code> command can be run to check and see if the changes are staged.</p> git status after staging changes<pre><code>On branch main\nYour branch is up to date with 'origin/main'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   README.md\n</code></pre>"},{"location":"Notes/Git/#committing-changes","title":"Committing changes","text":"<p>Committing in the context of git means to save a snapshot of the state of a file or multiple files in the version history. Commits are like save points to which the code base can be reverted to. The command <code>git commit</code>  can be used to commit changes.</p> Committing changes to a repository<pre><code># Commit message provided via the command\ngit commit -m \"Commit Title\" -m \"Commit description\"\n# Commit message provided via the default git text editor*\ngit commit </code></pre> <p>Upon running the command, git saves the changes to the version history and produces a message similar to the one showcased below. However, this can also be silenced with the <code>-q</code> flag or make it more detailed with the <code>-v</code> flag.</p> <p>Note: During the installation of git or via the global config options, it is possible to set the default text editor for git. This text editor is used when input from the user is required such as in case of supplying a commit message.</p> <p>[!info] Writing good commit messages Committing is at the core of the git workflow, and good commit messages are very important in communicating the changes made by the code to the existing project. This makes it easier to follow the changes for future reference or to aid in troubleshooting or bug hunting.</p> <p>The following are some of the guidelines for writing a good commit message</p> <ol> <li>Keep it short and concise - A good commit message should be short and to the point. It should describe the changes made in the commit in a clear and concise manner.</li> <li>Use the imperative mood - A commit message should be written in the imperative mood. This means using command-like language, such as \"Fix bug\" or \"Add new feature\".</li> <li>Provide context - A commit message should provide context for the changes made in the commit. It should answer questions such as \"Why was this change made?\" and \"What problem does it solve?\"</li> <li>Use the body for more detail - If necessary, provide more detail in the body of the commit message. This can include a description of the changes made, any relevant information about the code or files modified, and any necessary instructions for other developers.</li> <li>Follow any guidelines set by the project - Some projects may have specific guidelines or conventions for writing commit messages. Make sure to follow any guidelines set by the project to ensure consistency and clarity. </li> </ol> <p>[!info] Fixing (or) amending the last commit Sometimes, a change needs to be done on the last commit. This could be due to accidentally missing file(s) or typos in the commit messages and so on. The amend flag to the <code>git commit</code> command performs the redo of the previous commit. Before running a commit with the <code>amend</code> flag, changes can be made to the codebase to correct the mistakes performed in the previous commit if required.</p> <p>After the changes are made, when ready to perform the commit, the command, <code>git commit</code> is run with <code>amend</code> flag as <code>git commit --amend</code>. Now git opens the commit message for the commit in the default text editor configured. By default, git uses <code>vim</code> as the text editor of choice. Now, the necessary changes can be made to the commit messages. By default, the previous commit messages are taken as the base, allowing changes to be made when committing.</p>"},{"location":"Notes/Git/#getting-the-history-log-of-previous-commits","title":"Getting the history (log) of previous commits","text":"<p>To know the commit history of a git repository, the <code>git log</code> command can be used. By default, a git log command returns the following 4 pieces of information.</p> <ol> <li>Commit hash and branch information - Hash (digital uniquely identifying string of characters) uniquely identifies the commit and the branch information lets the user know which repository, branch and location the commit was made to.</li> <li>Author - Shows the author who made the commit.</li> <li>Timestamp - Shows when the commit was performed.</li> <li>Commit Message - Shows the message provided by the commit author when performing the commit.</li> </ol> <p>Command:</p> <pre><code>git log\n</code></pre> <p>Command Output (Example)</p> <pre><code>commit e5a5f55a235c5d2f9a4e4de4d41fa71a1a07c51f (HEAD -&gt; master, origin/master)\nAuthor: John Doe &lt;johndoe@example.com&gt;\nDate:   Fri May 7 14:30:15 2021 -0400\n\n    Add new feature\n\ncommit 0123456789abcdef0123456789abcdef01234567\nAuthor: Jane Smith &lt;janesmith@example.com&gt;\nDate:   Wed May 5 10:45:32 2021 -0400\n\n    Update documentation\n\ncommit 9876543210fedcba9876543210fedcba98765432\nAuthor: John Doe &lt;johndoe@example.com&gt;\nDate:   Mon May 3 16:20:49 2021 -0400\n\n    Initial commit\n</code></pre>"},{"location":"Notes/Git/#ignoring-files-and-directories","title":"Ignoring files and directories","text":"<p>A <code>gitignore</code> is a configuration file used to specify git to ignore files and folder when tracking changes in a repository. </p> <p>This is useful in cases where these files and folders are log files, secrets, build artifacts, lock files or binary files. These files might be changing frequently or can be generated by the end-user whenever required, and hence hold no value to be tracked by git.</p> <p>Setting up an appropriate <code>gitignore</code> file aids in maintenance of a cleaner, more manageable and less cluttered. </p> <p>Following are some of the important questions and their corresponding workflows to keep in mind when working with <code>.gitignore</code> files. </p> <ol> <li>What file and file format is the <code>.gitignore</code> file - <code>gitignore</code> files are created as <code>.gitignore</code> (without extension) files.</li> <li>Where to place the file? - <code>gitignore</code> files are usually created at the root of the repository.</li> <li>What if I place the <code>.gitignore</code> file in a sub-directory? - If a <code>.gitignore</code> file is placed in a child directory to the root directory of the git repository, git uses that <code>.gitignore</code> file to ignore files in that particular directory specifically. Tt is to be noted that a <code>gitignore</code> file at a directory is applicable only to that directory and its children and not to its parents or siblings.</li> <li>Okay, so what is the best practice for <code>.gitignore</code> files? - It is recommended to not have multiple <code>.gitignore</code> files per repository to avoid conflicts and complexity. Also, when a repository is collaboratively maintained, it is important that all the collaborators  have the same <code>.gitignore</code> file, to avoid ignore conflicts.</li> <li>Is the <code>.gitignore</code> file tracked by git? - Yes, <code>.gitignore</code> files must be tracked by git in order for git to ignore files and folders as per the instructions stated.</li> <li>What if a new file/folder to be ignored is added to the <code>.gitignore</code> file after it is being tracked by git? - Once git starts tracking a particular file/folder, git will continue tracking the file even after the <code>.gitignore</code> file is modified to ignore the file/folder. In order to remove the file from git actively tracking the file/folder, there are two options<ul> <li>Remove the file/folder from the repository - This process completely deletes the file or folder that needs to be stopped being tracked. This can be done using <code>git rm &lt;file&gt;</code> command. Post this command, the file will be removed from git's tracking as well from the repository.</li> <li>Remove the file/folder from git tracking only - This removes the file/folder that needs to be stopped being tracked from git's tracking. This can be done using <code>git rm --cached &lt;file&gt;</code> command. Post this command, the file will be removed from git's tracking, but will remain in the repository.</li> </ul> </li> <li>How to specify files/folders for ignoring? - <code>.gitignore</code> accepts files and folders as individual entities as well as with wildcard characters. The following snippet captures some of the common formats and sequences followed when ignoring files and folders in git repositories. </li> </ol> Commonly used gitignore formats<pre><code># ignore a specific file\nsome-file.txt\n\n# ignore all files with a specific extension\n*.log \n\n# ignore a specific directory\nmy-directory/\n\n# ignore directories with a certain name\n**/log-files\n\n# ignore all files and sub-directories in a directory\nlogs/**\n\n# ignore specific files in a directory and its sub-directories\nlogs/*.log\n\n# ignore files that match a pattern (rule negation)\n*.log\n!important.log\n</code></pre>"},{"location":"Notes/Git/#branching","title":"Branching","text":"<p>In git, branching refers to the creation of a new line of development from the existing line. Here, the line of development is referred to as branch, so called because it resembles the branches of a tree. </p> <p>Essentially, a branch is a pointer to a specific commit made in history, pointing to the state of the codebase at that point in time. Any file or folder in each branch, once created, can be changed, deleted, modified or added without affecting the parent branch it was created from as long as the author of those commits wishes to keep them separate. Essentially, commits in each branch are independent of other branches.</p> <p>Once the author decides to carry over the changes to the parent branch, an operation called as merging can be done.</p> <p>Git always operates in a branch. Unless changed, git creates a default branch by the name <code>master</code> or <code>main</code> whenever a new repository is created with <code>git init</code>. </p> <p>[!info] Master v Main <code>master</code> and <code>main</code> are both used as names for the default branch created by git when initializing a repository. While any name is allowed to be set as the default name, these two are in common use.</p> <p>Over time, the name of the default branch has evolved. Several community members found the term <code>master</code> being associated with slavery and racism. Hence they advocated and started using a better term, <code>main</code> as the default branch name. </p> <p>Git works no matter what name is set as the default branch name, and the preference ultimately needs to be set by the owner of the repository or governing principles in case of an organization or an open-source project team.</p> <p>To set or change the default branch name, use the <code>git config</code> command by supplying the new name for the branch. Reference snippet is provided below.</p> set/change global branch name configuration<pre><code>git config --global init.defaultBranch main\n</code></pre> <p>[!info] What is the HEAD? In git, HEAD is a reference to the current commit in a repository, pointing to the tip of the current branch where the most recent commit was made on that branch. In simpler terms, HEAD is a pointer to the last commit of the current branch. </p> <p>The <code>git branch</code> command is extensively used to manipulate branches. Following are some of the most common implementations of the <code>git branch</code> command.</p> git branch command implementations<pre><code># list all local branches\ngit branch\n\n# list all remote branches\ngit branch -r\n\n# list both local and remote branches\ngit branch -a\n\n# show SHA-1 commit ID \ngit branch -v\n\n# rename a branch (HEAD on the branch)\ngit branch -m bug-fixes\n\n# rename a branch - forcefully (HEAD on the branch)\ngit branch -M bug-fixes\n\n# delete a branch (HEAD on another branch)\ngit branch -d bug-fixed\n\n# delete a branch - Forcefully (HEAD on another branch)\ngit branch -D bug-fixed\n</code></pre>"},{"location":"Notes/Git/#switching-branches","title":"Switching branches","text":"<p>The command <code>git switch</code> can be used to switch from one branch to another. Both <code>git switch</code> and <code>git checkout</code> are commands that can be used to switch to new branches. </p> <p><code>git checkout</code> used to be the only way to change branches in older versions of git (prior to version 2.23). In newer versions of git (since version 2.23), the command <code>git switch</code> was introduced. </p> <p><code>git switch</code> is aimed at providing an intuitive and streamlined way of changing branches in git repositories in branching and committing.</p> <p>Following are some of the differences between <code>git checkout</code> and <code>git switch</code> commands.</p> <ol> <li>Simplistic - <code>git switch</code> command is simpler as it takes only one argument, where <code>git checkout</code>, being able to do more complex things, is inherently more complex.</li> <li>Less error prone - Due to its complex nature, <code>git checkout</code> command is more error-prone to the simplistic git switch command</li> <li>Data loss protection - The <code>git switch</code> command has built-in checks to prevent data loss, when trying to switch to a different branch with uncommitted changes in the working branch, which git checkout lacks, which may lead to data loss. When trying to switch branches with uncommitted changes, the <code>git switch</code> command prompts to <code>commit</code> or <code>stash</code> the changes.</li> </ol> <p>Commands:</p> git switch and git checkout to change branches<pre><code># switching to a new branch with git switch\ngit switch bugfix\n\n# create and switch to a new branch\ngit switch -c bugfix\n\n# switching to a new branch with git checkout\ngit checkout bugfix\n</code></pre>"},{"location":"Notes/Git/#merging-branches","title":"Merging branches","text":"<p>In git, merging is the process of combining changes from different branches and integrating them into a single branch. When two branches are merged, git makes a new commit that combines the changes from both the branches. </p> <p>By default, git manages conflicts when merging two branches and performs a new commit if necessary. To merge branches, first switch to the branch into which the changes need to be recorded (target branch) using <code>git switch</code> or <code>git checkout</code> commands. Next, merge the source branch using the git merge command.</p> merging branches<pre><code># merging a branch to the main branch (HEAD not on bug-fixed)\ngit merge bug-fixed\n</code></pre> <p>The following are some of the most commonly used types of merges in git.</p> <ol> <li>Fast-forward merge - A fast-forward merge occurs when the branch you are merging into has not diverged from the branch you are merging in any way. In this case, Git can simply move the pointer of the branch you are on to the latest commit on the other branch. This type of merge is fast because it does not create a new merge commit.</li> <li>Recursive merge - A recursive merge is the default merge strategy used by Git. It is used when the branches you are merging have diverged and cannot be fast-forwarded. Git creates a new merge commit that combines the changes from both branches. In this case, git prompts the merge author for a commit message for the new commit that arises from merging the two branches.</li> <li>Octopus merge - An octopus merge is a type of recursive merge that allows you to merge multiple branches into a single branch at the same time. This is useful when you have several branches that you want to integrate into a single codebase.</li> <li>Squash merge - A squash merge allows you to merge changes from a feature branch into another branch as a single commit. This can be useful if you want to keep the commit history of your main branch clean and concise.</li> <li>Rebase merge - A rebase merge is a way of integrating changes from one branch into another by replaying the changes made in the source branch on top of the target branch. This can be useful when you want to keep the commit history linear and avoid creating merge commits.</li> </ol> <p>Merge Conflicts occur in git when two branches are merged and have changes in the same file(s), that git cannot automatically merge them. This is because, git might not know which changes to keep and which changes to discard. Merge conflicts typically occur, when the same section of a file is modified in both the branches.</p> <p>Merge conflicts need to be manually resolved before a commit can be made. Changes in both the branches are reviewed and the appropriate content is kept, discarding the one that is not required.</p> <p>The following snippet shows how a merge conflict is presented to the merge author to be manually resolved.</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD (Current Change) \nSome changes  in the existing branch\n=======\nSome changes that are incoming to the existing branch\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; NEW-BRANCH (Incoming Change)\n</code></pre> <p>The following are the steps to resolve a merge conflict</p> <ol> <li>Make the essential changes on the file.</li> <li>Remove the conflict markers</li> <li>Stage the file with <code>git add</code> </li> <li>Commit the file with <code>git commit</code></li> </ol> <p>It is important to note that merge conflicts are very time-consuming and complex especially when a lot of changes are conflicting or when multiple files are in conflict.</p> <p>Here are some steps to take to avoid merge conflicts</p> <ol> <li>Keep the branches small - One of the main causes of merge conflicts is when multiple developers are working on the same file or section of code. To minimize the risk of conflicts, it's a good idea to break up the work into small, focused branches that only modify a few files or lines of code.</li> <li>Pull frequently - Before starting to work on a branch, make sure to pull the latest changes from the remote repository (if applicable) to ensure that the branch is up-to-date with the latest changes made by other developers. This can help prevent conflicts that arise from changes made by other developers.</li> <li>Communicate with the team - If changes to the same section is required and known, it's a good idea to communicate with the other developers beforehand to coordinate your efforts and avoid conflicts.</li> <li>Use descriptive commit messages - When making a commit, make sure to use a descriptive commit message that explains what changes were made. This can help other developers understand the changes and can help prevent conflicts that arise from misunderstandings.</li> <li>Test the changes - Before merging branches, make sure to test the changes thoroughly to ensure that they work as expected. This can help prevent conflicts that arise from bugs or errors in the code.</li> <li>Use merge tools - There are several merge tools available that can help resolve conflicts more easily. These tools can highlight conflicting changes and allow comparing and merging the changes more easily.</li> </ol> <p>[!info] Conflict Resolution - IDE Tools Most IDEs come with built-in tools to handle and resolve merge conflicts. These could include, but limited to accepting the current change (from the target branch), accepting changes from the incoming branch, accepting both changes and so on. </p> <p>It is important to learn to use these tools that are built into these IDEs to make the process easier.</p>"},{"location":"Notes/Git/#finding-the-difference","title":"Finding the difference","text":"<p>The <code>git diff</code> command displays the differences between the two versions of a file using a unified diff format, which shows the added and removed lines in the file. The output of the command can be customized using various options and flags to change the format, scope, and level of detail of the output. <code>git diff</code> just provides information and does not alter the repository in any form (similar to <code>git log</code> and <code>git status</code>).</p> <p>Following section explains the general output of the git diff command and how to make sense of what each part means.</p> <pre><code>diff --git a/Shopping-List.md b/Shopping-List.md\nindex 47e4552..08c9a76 100644\n--- a/Shopping-List.md\n+++ b/Shopping-List.md\n@@ -5,3 +5,10 @@ Store: David's Store\n ### Monthly Shopping Items\n Get the following things each month\n+Corn Flour\n+Jam\n+Chocolate Spread\n+Noodles\n+Rice\n+Carrots\n+Tomatoes\n Do not forget to take a bag to carry the grocery items. \n</code></pre> <p>Some of the most common implementations of git diff are given below for reference</p> <pre><code># Differences between working directory and staging area\n# These are changes not staged for commit\ngit diff\n\n# Differences between staging area and last commit\n# These are changes that staged and are yet to be committed\ngit diff --staged\ngit diff --cached\n\n# Differences between working directory and a particular commit\n# This shows the changes since a particular commit\ngit diff &lt;commit&gt;\ngit diff HEAD~2\ngit diff 4a23590..2c63590\n\n# Differences between the current branch and another branch\n# This shows what changes have been made across files\ngit diff &lt;branch&gt;\ngit diff bugfix # diff between current branch and bugfix branch\ngit diff bigfix..main\ngit diff bigfix main\n\n# NOTE: All these changes can be directed towards a specific file\ngit diff HEAD feature.js\ngit diff HEAD feature.js app.js\n</code></pre>"},{"location":"Notes/Git/#stashing-the-changes","title":"Stashing the changes","text":"<p>Stashing is the process of temporarily saving changes in a repository into a stash, without committing those changes. This returns a clean working directory, where the it leaves room for other operations such as branch switching, committing other changes and so on. </p> <p>The <code>git stash</code> command is used to perform stashing. Following are some of the most commonly used stashing operations.</p> <ol> <li>Stash Changes - To stash current changes, run <code>git stash save</code> or simply <code>git stash</code>. This will save both the modified and staged files in a new stash.</li> <li>View Stashes - To view a list of all available stashes, run <code>git stash list</code>. It will display the stash index number, description, and the branch where the stash was created.</li> <li>Apply Stash - To apply the most recent stash and restore the changes to the working directory, run <code>git stash apply</code>. This will merge the changes from the stash into the current branch.</li> <li>Apply Specific Stash - If multiple stashes exist, a specific stash can be applied by specifying its index number, such as <code>git stash apply stash@{2}</code>. The stash number can be obtained via the <code>git stash list</code> command.</li> <li>Drop Stash - When a stash is no longer needed, it can be removed from the stash stack using <code>git stash drop stash@{1}</code>. This action cannot be undone.</li> <li>Pop Stash - To apply the most recent stash and remove it from the stash stack in one step, run <code>git stash pop</code>.</li> <li>Clear the stash - To clear out the entire stash, run <code>git stash clear</code>.</li> </ol> <pre><code># Save a stash with description\ngit stash save \"Boss asked me to switch branches\"\n# View all stashes\ngit stash list\n\n# Apply the most recent stash to the working directory\ngit stash apply\n\n# Apply a specific stash to the working directory\ngit stash apply stash@{2}\n# Remove/delete a specific stash\ngit stash drop stash@{3}\n# Apply and remove the most recent stash\ngit stash pop\n\n# Apply and remove a specific stash\ngit stash pop stash@{2}\n</code></pre> <p>Note - It is possible to save a stash in one branch and then <code>git stash apply</code> or <code>git stash pop</code>  them in another branch. This is done by making changes in a branch, stashing them, switching to another branch with <code>git switch &lt;branch&gt;</code>, then running <code>git stash apply</code> or <code>git stash pop</code> .</p>"},{"location":"Notes/Git/#checking-out-an-old-commit","title":"Checking out an old commit","text":"<p>To checkout the state of the repository at a specific commit's point in time, the <code>git checkout</code> command can be used along with the commit identifier such as the commit hash.</p> <p>When an older commit is checked out, git enters what is called as a detached HEAD state. In this state, git allows the user to explore the codebase of the repository at that point in time and facilitates making changes if needed. This basically moves the HEAD to that specific commit, where usually HEAD refers to a branch and not a specific commit.</p> <p>The following outline specifies the workflow for working with older commits.</p> <ol> <li>Checking out an old commit - To checkout an older commit, a commit identifier such as the commit hash (at least first 7 characters) must be known. With the identifier information, use the <code>git checkout &lt;commit_identifier&gt;</code> command. Now, git moves the HEAD to that specific commit and enters the detached HEAD state.</li> <li>Detached HEAD state - The state so called, as HEAD usually refers to an entire branch and not a single commit is when the HEAD points to the commit of interest. Any changes made in this state will not be associated with a branch.</li> <li>Inspecting commit and making changes - Any changes made at this point will not be associated to a branch and will be lost unless saved specifically. To save the changes, a new branch can be created at the current commit level.</li> <li>Returning to a branch - To return to a branch or create a new branch, the <code>git checkout</code> command can be used with the reference to the branch name.</li> <li>Re-attaching the HEAD - Once the HEAD moves to a specific branch, the HEAD is said to be in attached state once again as it goes back to referencing a branch rather than a commit when it first detached while checking out an older commit.</li> </ol> <pre><code># Checking out an older commit\ngit checkout 4e237h5\n\n# Detached HEAD state\n# Inspecting commit and making changes\n# Attaching HEAD / Returning to a branch\ngit checkout main\n</code></pre>"},{"location":"Notes/Git/#discarding-changes","title":"Discarding changes","text":"<p>If changes made after a commit is to be discarded, the command <code>git checkout</code> can be used. This reverts the state of the repository to the commit specified in the command. Doing this will remove all the changes that were made after the last commit.</p> <pre><code># Discarding changes from a specific file (Method 1)\ngit checkout HEAD fruits.txt\n\n# Discarding changes from all files (Method 1)\ngit checkout HEAD .\n\n# Discarding changes from a specific file (Method 2)\ngit checkout -- fruits.txt veggies.txt\n\n# Discarding changes from all files (Method 2)\ngit checkout -- .\n</code></pre> <p>Another command that can be used to perform the discarding of the changes since a commit is <code>git restore</code></p> <pre><code># Discarding changes from a specific file\ngit restore fruits.txt\n\n# Discarding changes from all files\ngit restore .\n\n# Reverting state to a specific commit for specific files\ngit restore --source HEAD~2 fruits.txt\n\n# Reverting state to a specific commit for all files\ngit restore --source HEAD~2 .\n</code></pre> <p>Note that following the <code>git checkout</code> and <code>git restore</code> commands to discard changes removes the uncommitted changes from the repository, thus using them with caution is recommended.</p>"},{"location":"Notes/Git/#un-staging-changes","title":"Un-staging changes","text":"<p>If the aim is just to un-stage the changes made in a repository, there-by keeping all the files in which the changes were made, again the <code>git restore</code> command can be used with the <code>--staged</code> flag.</p> <pre><code># Unstaging changes to a specific file\ngit restore --staged fruits.txt\n\n# Unstaging changes to all files\ngit restore --staged .\n</code></pre> <p>The same functionality, of removing the staged files can be done with the command <code>git reset</code> as well. The <code>git reset</code> command with the flag <code>--</code> un-stages the changes made to the repository that is not committed. </p> <pre><code># Un-staging all changes and revert to the previous commit\ngit reset --\n</code></pre> <p>It is to be notes that the git reset command works at the scope of a commit history, and thus will not allow to reset only one file. To un-stage the changes in one single file, use the <code>git restore</code> command. </p> <p>Note that running the git reset command without the -- flag behaves differently, and performs an undo on the last commit.</p>"},{"location":"Notes/Git/#undoing-commits","title":"Undoing commits","text":"<p>Sometimes, the commits made to a branch might have to be undone for various reasons. For this purpose, the <code>git reset</code> command can be used.</p> <p>The <code>git reset</code>  command is commonly specified with one of 3 flags, namely</p> <ol> <li>Soft Reset with <code>--soft</code> - Reverts back the branch pointer to a commit, but preserves the changes in the staging area. Changes in the working directory and staging area are preserved. </li> <li>Mixed Reset with <code>--mixed</code> - This is the default option, when no flag is specified. Reverts back the branch pointer to a commit, and matches the staging area to the commit. Changes in the working directory are preserved.</li> <li>Hard Reset with <code>--hard</code> - Reverts back the branch pointer to a commit. This discards any and all changes to the working directory and the staging area. Needless to say, care must be taken before performing this action, as all changes will be lost.</li> </ol> <pre><code># Soft Reset - Preserve changes in working directory &amp; staging area\ngit reset --soft 423a145\n\n# Mixed Reset - Preserve changes in working directory\ngit reset --mixed 423a145\n\n# Mixed Reset - DOES NOT PRESERVE CHANGES\ngit reset --hard 423a145\n\n# NOTE: Also accepts dynamic HEAD pointers\ngit reset 423a145 HEAD~2\n</code></pre>"},{"location":"Notes/Git/#reverting-commits","title":"Reverting commits","text":"<p>The command <code>git revert</code> is used to create a new commit that sets the state of the repository as per a previous commit. This allows to safely revert/undo a commit while preserving the commit history.</p> <p>Here, a new commit is made that reverses the changes made in the specified commit. This ensures that the commit history remains intact and that the original commit is not removed or modified. </p> <p>Here are some key pointers when it comes to git revert</p> <ul> <li>It creates a new commit, so the commit history is preserved.</li> <li>It's a safe way to undo changes, especially in shared repositories where you don't want to modify the existing history.</li> <li>It can revert a single commit or a range of commits</li> </ul> <pre><code># Revert to a previous commit\ngit revert 423a145\n</code></pre> <p>It is important to note that the command <code>git revert</code> functions at the commit level and will not be able to revert a specific file. To revert specific changes within a commit, other git commands such as <code>git cherry-pick</code>, <code>git reset</code> or interactive rebase via <code>git rebase -i</code> shall be used.</p> <p>However it is to be noted that, <code>git revert</code> can introduce conflicts if the changes being reverted conflict with the subsequent changes. Thus, it is recommended to review the changes and test the reverted state before sharing the code to a shared repository. </p>"},{"location":"Notes/GoLang/","title":"Get-Set-GoLang","text":""},{"location":"Notes/GoLang/#introduction","title":"Introduction","text":"<p>Go, also referred to as Golang is a programming language developed by Google in 2007. It's designed for simplicity, performance, and concurrency. Go has a built-in concurrency model with goroutines and channels. It includes a garbage collector for automatic memory management. Go is popular for building high-performance systems and network applications. Go modules is the built-in package manager for dependency management. Go is a great option for developers who want to build fast, efficient, and scalable systems.</p>"},{"location":"Notes/GoLang/#golang-history-and-development","title":"GoLang History and Development","text":"<p>The development of Golang started in 2007. The language was first announced publicly in November 2009 and was officially released in March 2012.</p> <p>Go was created by a team of three developers at Google, Robert Griesemer, Rob Pike, and Ken Thompson, with the goal of creating a new programming language that was more productive, efficient, and scalable than existing languages.</p> <p>Go was designed to address some of the limitations of other programming languages, such as slow compilation times, verbose syntax, and lack of support for concurrency. The language was also designed to be easy to learn and use, with a minimalist syntax and a focus on simplicity.</p> <p>Go's development was heavily influenced by other programming languages, particularly C, Pascal, and the programming language Alef, which was also developed by Rob Pike and others at Bell Labs in the 1980s.</p> <p>Go's development has been guided by an open source community, with contributions from many developers around the world. The language has seen rapid adoption, particularly in the field of cloud computing,distributed systems and DevOps. Today, Go is used by many major companies, including Google, Uber, Dropbox, and Netflix, among others.</p> <p>Go continues to evolve, with new releases and updates bringing new features and improvements to the language. The language has gained a reputation for being fast, efficient, and easy to use, and is increasingly seen as a viable alternative to other popular programming languages such as Python, Ruby, and Java.</p>"},{"location":"Notes/GoLang/#language-syntax","title":"Language Syntax","text":"<p>The syntax of Golang is influenced by C, but it also includes features from other programming languages, such as Pascal and Modula-2. Here are some key features of the Golang syntax:</p> <ol> <li>Simple and readable - The syntax of Golang is designed to be simple and readable, with a minimal amount of keywords and syntax. This makes it easy for developers to understand and maintain code.</li> <li>Statically typed - Golang is a statically typed language, which means that variable types are declared at compile time. This helps to catch errors early in the development process.</li> <li>Package-based - Golang organizes code into packages, which are collections of functions, types, and variables. Packages can be imported and used by other packages, making it easy to reuse code and manage dependencies.</li> <li>Pointers - Golang includes pointers, which are variables that hold the memory address of another variable. Pointers are used to create more efficient code and to allow for direct manipulation of memory.</li> <li>Concurrency support - Golang includes built-in support for concurrency through goroutines and channels. Goroutines are lightweight threads that allow for parallel execution of code, while channels provide a safe and efficient way to share data between concurrent processes.</li> <li>Garbage collection - Golang includes a garbage collector that automatically manages memory, freeing developers from having to worry about manual memory management.</li> <li>Error handling - Golang includes a built-in error handling system, which makes it easy to handle and propagate errors throughout a program.</li> </ol> <p>Overall, the syntax of Golang is designed to be simple, readable, and efficient, with a focus on concurrency and error handling. These features make Golang a great choice for building high-performance systems and network applications</p> <p>Go is designed to be simple to understand, code and learn. With this in mind, a typical go development environment consists of a set of tools that make development in go a pleasurable experience.</p>"},{"location":"Notes/GoLang/#basic-concepts","title":"Basic Concepts","text":"<p>Before starting anything, the first thing to learn in any programming language  is to understand the help system. To access the built-in help system within Golang, the following command can be used.</p> InputOutput <pre><code>    go help\n</code></pre> <pre><code>    Go is a tool for managing Go source code.\n\nUsage:\n\n    go &lt;command&gt; [arguments]\n\nThe commands are:\n\n    bug         start a bug report\n    build       compile packages and dependencies\n    clean       remove object files and cached files\n    doc         show documentation for package or symbol\n    env         print Go environment information\n    fix         update packages to use new APIs\n    fmt         gofmt (reformat) package sources\n    generate    generate Go files by processing source\n    get         add dependencies to current module and install them\n    install     compile and install packages and dependencies\n    list        list packages or modules\n    mod         module maintenance\n    work        workspace maintenance\n    run         compile and run Go program\n    test        test packages\n    tool        run specified go tool\n    version     print Go version\n    vet         report likely mistakes in packages\n\nUse \"go help &lt;command&gt;\" for more information about a command.\n\nAdditional help topics:\n\n    buildconstraint build constraints\n    buildmode       build modes\n    c               calling between Go and C\n    cache           build and test caching\n    environment     environment variables\n    filetype        file types\n    go.mod          the go.mod file\n    gopath          GOPATH environment variable\n    gopath-get      legacy GOPATH go get\n    goproxy         module proxy protocol\n    importpath      import path syntax\n    modules         modules, module versions, and more\n    module-get      module-aware go get\n    module-auth     module authentication using go.sum\n    packages        package lists and patterns\n    private         configuration for downloading non-public code\n    testflag        testing flags\n    testfunc        testing functions\n    vcs             controlling version control with GOVCS\n\nUse \"go help &lt;topic&gt;\" for more information about that topic.\n</code></pre> <p>Most Golang projects start with a <code>go mod init</code> command being run at the terminal. It goes something like this</p> Initializing a Go Project<pre><code># General Syntax\ngo mod init &lt;some-name/repo-name&gt;\n\n# Example 1: Initialize a Hello World project\ngo mod init hello-world\n\n# Example 2: Initialize a Standalone Go Project\ngo mod init github.com/GoPal/Hello-World\n</code></pre> InputOutput <pre><code>    go mod init hello-world\n</code></pre> <pre><code>    go: creating new go.mod: module hello-world\n</code></pre> <p>The result of this operation is the creation of a <code>go.mod</code> file in the directory where the command is run.</p> <p>Why <code>go mod init</code>?</p> <p><code>go.mod</code> is a file that is used to track dependencies for the current go project. the following are some of the reasons why initializing a go module is considered best practice.</p> <ol> <li>Dependency Management - <code>go mod init</code> is essential for managing dependencies in a Golang project. The <code>go.mod</code> file created by <code>go mod init</code> command tracks the versions of dependencies used in the project and ensures that they are compatible with each other.</li> <li>Versioning - <code>go.mod</code> file assists in versioning of the code and its dependencies. This assists in easy sharing and reuse of the same code across teams and projects.</li> <li>Portability - <code>go.mod</code> file is a self-contained used, meaning that it can be moved to different environments and build systems.</li> <li>Compatibility - <code>go mod init</code> is designed to be backwards-compatible, meaning that it can be run on older Golang projects and it would still work without any issues.</li> </ol> <p>By convention, the first thing to do in a programming language is try and print <code>Hello World!</code>. That is exactly the goal of this section. In Golang, the code is organized into packages. Every functionality of the language has to be imported to be used. Consider the following example.</p> Go - Hello World<pre><code>package main\nimport \"fmt\"\nfunc main() {\nfmt.Println(\"Hello World!\")\n}\n</code></pre> <p>What is <code>package main</code> ?</p> <p>Here, the <code>package main</code> is a declaration usually found in files named <code>main.go</code>. These are declarations that the go compiler uses to compile the files to an executable. It tells the compiler that this is intended to be an executable program and not a package that is intended to be imported into other programs.</p> <p><code>package main</code> must be the first line of the code. and the file must contain a <code>main</code> function. this function is the entry point for code execution, where the code/program logic begins evaluation.</p> <p>Summarizing, the <code>package main</code> is a declaration on <code>main.go</code> files indicates the go compiler to build an executable program out of it and that the program contains a main function to act as the entry point for code execution.</p> <p>What are we importing?</p> <p>In Golang, the import statement is used to include code from other packages in the current program. When a package is imported, all the functions, types and variables exposed by the package will be available to use by the importing program.</p> <p>To import a package, use the following syntax</p> Importing Go packages<pre><code># Importing a single package\nimport \"fmt\"\n# Importing multiple packages\nimport {\n\"fmt\"\n\"math\"\n\"bufio\"\n}\n</code></pre> <p>As a best practice, do not import packages that are not used by the program. Import what is really needed to run the program.</p>"},{"location":"Notes/GoLang/#data-types-and-variables","title":"Data Types and Variables","text":""},{"location":"Notes/GoLang/#data-types","title":"Data Types","text":"<p>In GoLang, there are several built-in data types that assist in creating variables and assigning values to them, so that they can be manipulated in programs. The following is the list of the data types available in Golang.</p>"},{"location":"Notes/GoLang/#boolean","title":"Boolean","text":"<ul> <li>The <code>bool</code> data type represents a true or false value.</li> </ul>"},{"location":"Notes/GoLang/#numeric","title":"Numeric","text":"<ul> <li><code>int</code> and <code>uint</code> - Signed and unsigned integers of various sizes (int8, int16, int32, int64, uint8, uint16, uint32, uint64).</li> <li><code>float32</code> and <code>float64</code> - Floating-point numbers of varying precisions.</li> <li><code>complex64</code> and <code>complex128</code> - Complex numbers with floating-point real and imaginary parts.</li> </ul> <p>The following table captures the permitted values along with the memory allocation for each of the numeric data types</p> Numeric Type Allocated Size Permitted Values uint8 8-bits 0 - 255 uint16 16-bits 0 - 65535 uint32 32-bits 0 - 4294967295 uint64 64-bits 0 - 18446744073709551615 int8 8-bits -128 - 127 int16 16-bits -32768 - 32767 int32 32-bits -2147483648 - 2147483647 int64 64-bits -9223372036854775808 to 9223372036854775807 float32 32-bits IEEE-754 floating point numbers float64 64-bits IEEE-754 floating point numbers complex64 64-bits Complex numbers with float32 real and imaginary parts complex128 128-bits Complex numbers with float32 real and imaginary parts"},{"location":"Notes/GoLang/#string","title":"String","text":"<ul> <li>The <code>string</code> data type represents a sequence of Unicode characters.</li> <li>Strings are immutable, meaning once they are created, they cannot be changed.</li> <li>A string's length is the number of bytes it occupies. It could be 0 for an empty string, but never negative. The length can be computed with the built-in function, <code>len</code>.</li> <li>Individual elements of the string can be accessed using the index of the character such as <code>string[0]</code> to <code>string[len(string) - 1]</code>. </li> <li>However, it is not allowed to take the address of an individual elements of a string.</li> </ul>"},{"location":"Notes/GoLang/#array","title":"Array","text":"<ul> <li>An <code>array</code> is a fixed-size collection of elements of the same type.</li> </ul>"},{"location":"Notes/GoLang/#slice","title":"Slice","text":"<ul> <li>A <code>slice</code> is a dynamic array that can grow or shrink as needed.</li> </ul>"},{"location":"Notes/GoLang/#map","title":"Map","text":"<ul> <li>A <code>map</code> is a collection of key-value pairs.</li> </ul>"},{"location":"Notes/GoLang/#struct","title":"Struct","text":"<ul> <li>A <code>struct</code> is a composite data type that allows developers to group related values of different data ty</li> </ul>"},{"location":"Notes/GoLang/#interface","title":"Interface","text":"<ul> <li>An <code>interface</code> is a type that defines a set of methods that a type must implement to be considered an instance of that interface.</li> </ul>"},{"location":"Notes/GoLang/#pointer","title":"Pointer","text":"<ul> <li>A <code>pointer</code> is a variable that holds the memory address of another variable.</li> </ul> <p>In addition to these built-in data types, Golang also supports user-defined types, which can be created using the <code>type</code> keyword. Overall, the data types available in Golang provide developers with a flexible and powerful set of tools for creating and manipulating data in their programs.</p>"},{"location":"Notes/GoLang/#variables","title":"Variables","text":"<p>Now that the data types are known, the next logical step is to learn how to use them. There are several ways to declare a variable in Golang, the methods are stated below.</p> <p>Method 1: Using the <code>var</code> keyword and explicit data type declaration</p> <pre><code>// Variable declaration with explicit data type\nvar username string = \"John Doe\"\n</code></pre> <p>Here, a variable username was created with string data type, and declared a value of \"John Doe\"</p> <p>Possible errors: If the explicit data type does not match the value being supplied to the variable during initialization, the go compiler throws an error. The following code throws an error.</p> <pre><code>// Variable declaration with wrong explicit data type\nvar username int = \"John Doe\"\n</code></pre> <p>Method 2: Using the var keyword and implicit data type declaration</p> <pre><code>// Variable declaration with implicit data type\nvar user_id = \"EM001\"\n</code></pre> <p>This follows a syntax to create a variable and initialize a value to it, but here the go compiler implicitly selects the data type for the value supplied.</p> <p>Method 3: Using the short variable declaration (Walrus Operator)</p> <pre><code>// Variable declaration with short variable declaration\nage := 45\n</code></pre> <p><code>:=</code> is the short variable declaration operator, commonly referred to as the walrus operator (due to appearance resembling a walrus with tusks)  popularized by Russ Cox, one of the original developers of the language. The following are some key points to remember when it comes to the walrus operator. - It can be used only for variable declaration. To assign values to existing variables, the <code>=</code> operator is used.  - The scope of a variable declared with the walrus operator is within the function, and not the package level. To declare variables at the package level, the <code>=</code> operator must be used.</p> <p>Possible Errors: For short form variable declarations, the var keyword must not be used. If used, the go compiler throws an error.</p> <pre><code>// Illegal short form variable declaration\nvar age:= 45\n</code></pre> <p>Note: In Golang, it is not possible to initialize a variable with a value before declaration. Thus a declaration needs to be made either explicitly or implicitly. The 3 methods stated above all declare the variable and supply an initialization value, and are thus considered valid syntax. However, assigning a value to a variable, without declaration will make the go compiler throw an error as in go, the <code>=</code> operator is considered as an assignment operator. The following code produces an error.</p> <pre><code>// Variable value assignment without initialization\nage = 45\n</code></pre> <p>Method 4: Declaring multiple variables at once</p> <pre><code>// Multiple variables - same data types (explicit declaration)\nvar email, domain string = \"john@doecompany.com\", \"JDC-AP\"\n// Multiple variables - same type (:= operator)\nage, height := 25, 180\n</code></pre> <p>Possible Errors: When declaring multiple variables, all the variables must be of the same data type. Declaring multiple variables with multiple data types will lead to a <code>type mismatch</code> error.</p> <pre><code>// Illegal multiple variable declaration\nvar name, height = \"John Doe\", 180\n// Illegal multiple variable declaration\nvar name, email string, age int = \"John Doe\", \"john.doe@example.com\", 25\n</code></pre> <p>Method 5: Declaring variables without initial value</p> <p>In Golang, when a variable is just declared and not assigned a value, it takes a default value. The following code showcases the defaults.</p> <pre><code>var i int\nvar f float32\nvar b bool\nvar s string\nvar ptr *int\nvar m map[string]int\nvar sl []int\nvar ch chan int\nfmt.Println(i)    // Output: 0\nfmt.Println(f)    // Output: 0\nfmt.Println(b)    // Output: false\nfmt.Println(s)    // Output: \"\"\nfmt.Println(ptr)  // Output: nil\nfmt.Println(m)    // Output: map[]\nfmt.Println(sl)   // Output: []\nfmt.Println(ch)   // Output: nil\n</code></pre> <p>Method 6: Declaration of constants</p> <pre><code>const pi float64 3.14159\n</code></pre> <p>Possible Errors: Once a constant variable is declared, its value cannot be changed during the program's execution.</p>"},{"location":"Notes/GoLang/#operators","title":"Operators","text":"<p>Operators in any programming language facilitate arithmetic, logical and string operations on variables.</p> <p>Following are the different types of operators in Golang and a short description of what they do.</p>"},{"location":"Notes/GoLang/#arithmetic-operators","title":"Arithmetic operators","text":"<p>These operators are used to perform basic arithmetic operations such as addition, subtraction, multiplication, division, and modulus.</p> <p>The following are arithmetic operators in Go</p> <pre><code>+    addition\n-    subtraction\n*    multiplication\n/    division\n%    modulus\n</code></pre>"},{"location":"Notes/GoLang/#comparison-operators","title":"Comparison Operators","text":"<p>These operators are used to compare two values and return a Boolean value indicating the result of the comparison.</p> <p>The following are comparison operators in Go</p> <pre><code>==    equal to\n!=    not equal to\n&lt;     less than\n&lt;=    less than or equal to\n&gt;     greater than\n&gt;=    greater than or equal to\n</code></pre>"},{"location":"Notes/GoLang/#bitwise-operators","title":"Bitwise Operators","text":"<p>These operators are used to perform bitwise operations on integer values.</p> <p>The following are bitwise operators in Go</p> <pre><code>&amp;    bitwise AND\n|    bitwise OR\n^    bitwise XOR\n&lt;&lt;   left shift\n&gt;&gt;   right shift\n&amp;^   bitwise AND NOT\n</code></pre>"},{"location":"Notes/GoLang/#assignment-operators","title":"Assignment Operators","text":"<p>These operators are used to assign values to variables.</p> <p>The following are assignment operators in Go</p> <pre><code>=     simple assignment\n+=    addition assignment\n-=    subtraction assignment\n*=    multiplication assignment\n/=    division assignment\n%=    modulus assignment\n&lt;&lt;=   left shift assignment\n&gt;&gt;=   right shift assignment\n&amp;=    bitwise AND assignment\n|=    bitwise OR assignment\n^=    bitwise XOR assignment\n&amp;^=   bitwise AND NOT assignment\n</code></pre>"},{"location":"Notes/GoLang/#other-miscellaneous-operators","title":"Other Miscellaneous Operators","text":"<p>A few other operators exist in Go, to facilitate specific operations. </p> <pre><code>&amp;    address of operator\n*    pointer dereference operator\n&lt;-   channel send/receive operator\n:=   walrus operator (short variable declaration)*\n</code></pre> <p>*Note: The walrus operator is not a separate type of operator, but just a shorthand representation to declare and initialize a variable.</p>"},{"location":"Notes/GoLang/#type-conversions","title":"Type Conversions","text":"<p>Type conversions are actions done on values housed inside variables to convert them from one data type to another. Go supports the following types of type conversions.</p>"},{"location":"Notes/GoLang/#implicit-type-conversions","title":"Implicit Type Conversions","text":"<p>Implicit conversions are type conversions that are carried out automatically by  Golang for data types that are compatible with one another.</p> <p>One example of this conversion is conversion of values from integer to float when assigning to variables of float data type (as given below)</p> <pre><code>var num int = 10\nvar fnum float64 = num // Implicit conversion (int - float64)\nfmt.Println(fnum) // Output: 10.0\n</code></pre>"},{"location":"Notes/GoLang/#explicit-type-conversions","title":"Explicit Type Conversions","text":"<p>Explicit conversions are made when go is specifically instructed to convert a value from one data type to another, by means of a type casting expression.</p> <p>In Golang explicit type conversions can be done in the following ways</p>"},{"location":"Notes/GoLang/#using-type-casting","title":"Using Type Casting","text":"<p>This type of operation is applicable only to easily interchangeable data types such as conversions within the numerical data types. The following code snippet showcases an implementation of such a type casting in Golang.</p> <pre><code>var fnum float64 = 10.5\nvar inum int = int(fnum) // Type casting (float64 - int)\nfmt.Println(inum) // Output: 10\n</code></pre>"},{"location":"Notes/GoLang/#using-conversion-functions","title":"Using Conversion Functions","text":"<p>Golang provides specific conversions functions that can be used to convert data from one data type to another. </p> <p>The <code>strconv</code> package is one of the most commonly used type conversions packages used in Golang. </p> <pre><code>var str string = \"10\"\nvar num int = strconv.Atoi(str) // String - int\nfmt.Println(num) // Output: 10\n</code></pre> <p>Some other functions in the <code>strconv</code> go package are as follows. 1.  <code>Atoi()</code> - converts a string to an integer (<code>int</code>) 2.  <code>ParseInt()</code> - converts a string to an integer (<code>int64</code>) 3.  <code>ParseUint()</code> - converts a string to an unsigned integer (<code>uint64</code>) 4.  <code>ParseFloat()</code> - converts a string to a floating-point number (<code>float64</code>) 5.  <code>FormatInt()</code> - converts an integer (<code>int64</code>) to a string 6.  <code>FormatFloat()</code> - converts a floating-point number (<code>float64</code>) to a string</p> <p>Golang, out of the box provides conversion function for commonly used data formats such as binary, json, xml, csv, color codes and so much more. </p>"}]}